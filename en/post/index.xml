<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>All Blogs | PRIS-NLP Group</title>
    <link>https://pris-nlp.github.io/en/post/</link>
      <atom:link href="https://pris-nlp.github.io/en/post/index.xml" rel="self" type="application/rss+xml" />
    <description>All Blogs</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© PRIS-NLP 2022</copyright><lastBuildDate>Fri, 08 Apr 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://pris-nlp.github.io/images/icon_hu316c76060153165bc5df614349754290_164774_512x512_fill_lanczos_center_3.png</url>
      <title>All Blogs</title>
      <link>https://pris-nlp.github.io/en/post/</link>
    </image>
    
    <item>
      <title>Recent research overview of our research group</title>
      <link>https://pris-nlp.github.io/en/post/220408wzc/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://pris-nlp.github.io/en/post/220408wzc/</guid>
      <description>&lt;h2 id=&#34;adpl-adversarial-prompt-based-domain-adaptation-for-dialogue-summarization-with-knowledge-disentanglement&#34;&gt;&lt;strong&gt;ADPL: Adversarial Prompt-based Domain Adaptation for Dialogue Summarization with Knowledge Disentanglement&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;authors&#34;&gt;Authors&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/en/author/lulu-zhao/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;赵璐璐&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/fujia-zheng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑馥嘉&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/weihao-zeng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾伟豪&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/keqing-he/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/ruotong-geng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;耿若彤&lt;/a&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/weiran-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;conference&#34;&gt;Conference&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://sigir.org/sigir2022/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SIGIR 2022&lt;/a&gt; Full Paper&lt;/p&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;领域自适应是机器学习中的一个基本任务。在本文中，我们研究对话摘要任务中的领域迁移问题，试图借助源域的有标注数据迁移到无标注或少标注的目标域，进而提升低资源目标域下对话摘要的生成效果，可用于解决实际场景中小业务数据匮乏的挑战。传统的对话摘要领域迁移方法往往依赖于大规模领域语料，借助于预训练来学习领域间知识。该方法的缺点是实际语料收集难，对算力要求高，针对每一个目标域都需要进行耗时的预训练过程，效率低。因此，本文从微调的角度出发，提出了一种轻量级的解耦知识迁移方法ADPL，无需大规模的预训练过程，仅仅利用源域数据和少量的无标注目标域数据，即可实现高质量的对话摘要生成。具体来说，我们基于prompt learning的思想，针对对话摘要任务中的领域迁移问题，提出了三种特定的prompt结构：domain-invariant prompt (DIP), domain-specific prompt (DSP), 和task-oriented prompt (TOP)，其中 DIP 用来捕获领域间的共享特征，DSP用来建模领域特有知识，TOP用来促进生成流畅的摘要。在训练中，我们仅仅更新这些prompt相关的参数就可以实现领域间知识的解耦和迁移，相比较之前的预训练方法，训练高效环保，对机器的显存要求显著降低。同时，我们基于两个大规模的对话摘要数据集QMSum和TODSum构建了对话摘要领域迁移评测集，在两个评测集上取得了一致的最优效果，实验结果和消融分析都证明了本文提出方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;center&gt;&lt;font face=&#34;黑体&#34; size=3&gt;ADPL整体框架示意图&lt;/font&gt;&lt;/center&gt;
&lt;hr&gt;
&lt;h2 id=&#34;revisit-overconfidence-for-ood-detection-reassigned-contrastive-learning-with-adaptive-class-dependent-threshold&#34;&gt;&lt;strong&gt;Revisit Overconfidence for OOD Detection: Reassigned Contrastive Learning with Adaptive Class-dependent Threshold&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;authors-1&#34;&gt;Authors&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/en/author/yanan-wu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;吴亚楠&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/keqing-he/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/yuanmeng-yan/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;严渊蒙&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/qixiang-gao/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;高琪翔&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/zhiyuan-zeng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾致远&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/fujia-zheng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑馥嘉&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/lulu-zhao/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;赵璐璐&lt;/a&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/weiran-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;conference-1&#34;&gt;Conference&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://2022.naacl.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NAACL 2022&lt;/a&gt; Main Conference, Long Paper&lt;/p&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;在面向任务的对话系统中，域外意图（out-of-domain, OOD）检测是必不可少的。它旨在检测用户查询是否超出预定义意图范围（in-domain, IND），以避免执行错误的操作。由于OOD意图标注的复杂性，大多数工作都集中在无监督OOD检测上，即没有标记OOD数据，只有标记IND数据。而当前无监督域外检测方法均忽略了域外检测中的关键性挑战——神经网络的过自信问题。&lt;/p&gt;
&lt;p&gt;在本文中，我们对过自信问题进行了深入分析，并将其拆解为两方面：过自信OOD和过自信IND。基于此，我们分别提出了一种新的重分配对比学习(RCL)来区分语义相似的IND类别之间的意图表示，以缓解过自信OOD问题，以及一种自适应的类局部阈值机制来区分相似的IND和OOD样本，以缓解过自信IND问题。&lt;/p&gt;
&lt;p&gt;具体来说，对于过自信OOD问题，我们首先使用预训练的意图分类器在易混淆的IND类型中构建hard对比对（其中，具有相同真实标签但不同的预测标签称为hard positive pair，不同真实标签但相同预测标签称为hard negative pair），然后，基于构建的对比对训练一个新的模型，并通过监督对比学习来学习相似IND类别的鉴别性意图表示；对于过自信IND问题，不同于传统MSP、GDA使用单一全局阈值的方式，为考虑IND和OOD类别之间的关联性，我们为每个意图类别自适应赋予一个独立阈值，有效区分语义高度相似的IND和OOD样本，缓解过自信OOD问题。多个数据集上实验和分析证明了本文提出方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;domain-oriented-prefix-tuning-towards-efficient-and-generalizable-fine-tuning-for-zero-shot-dialogue-summarization&#34;&gt;&lt;strong&gt;Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;authors-2&#34;&gt;Authors&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/en/author/lulu-zhao/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;赵璐璐&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/fujia-zheng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑馥嘉&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/weihao-zeng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾伟豪&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/keqing-he/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/weiran-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/yanan-wu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;吴亚楠&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;conference-2&#34;&gt;Conference&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://2022.naacl.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NAACL 2022&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;introduction-2&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;现实生活中经常面临到新领域中数据标注稀缺的问题，为新领域进行标注耗时耗力，因此利用有限的源域注释数据为目标域开发低资源对话摘要模型至关重要。当前的生成式对话摘要方法缺乏对新领域的泛化能力，而现有的在摘要领域自适应问题上的研究通常是依赖于大规模的二次预训练。&lt;/p&gt;
&lt;p&gt;为了探索对话摘要领域自适应的轻量级微调方法，在本文中，我们提出了一种高效且可泛化的面向领域的Prefix-tuning模型（Domain-Oriented Prefix-tuning，DOP），在冻结的预训练模型的基础上，结合连续的prefix和离散的prompt表示，提高模型的领域自适应能力。具体来说，我们使用无监督 LDA提取的领域词来初始化连续提示向量，以获得前缀模块的初始参数和表示。我们还添加了一个面向领域的键值对前缀序列来增强经典注意力层，以交互方式获取知识并实现优化。除此之外，我们使用dialogue state和query作为离散prompt，引导模型关注对话中关键内容并增强对新领域的泛化能力。&lt;/p&gt;
&lt;p&gt;我们在两个多域对话摘要数据集 TODSum 和 QMSum 上进行零样本迁移实验并建立领域自适应benchmark， 充分的实验和定性分析证明了我们方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;disentangled-knowledge-transfer-for-ood-intent-discovery-with-unifified-contrastive-learning&#34;&gt;&lt;strong&gt;Disentangled Knowledge Transfer for OOD Intent Discovery with Unifified Contrastive Learning&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;authors-3&#34;&gt;Authors&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/en/author/yutao-mu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;牟宇滔&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/keqing-he/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/yanan-wu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;吴亚楠&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/zhiyuan-zeng/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾致远&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/hong-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐红&lt;/a&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/en/author/weiran-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;conference-3&#34;&gt;Conference&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.2022.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL 2022&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;introduction-3&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;本文研究域外(OOD)意图发现任务，该任务旨在将新出现的未知意图的样本按意图语义聚成不同类簇，这有助于任务型对话系统发展新的技能。不同于传统的文本聚类任务，域外意图发现需要考虑如何利用已知的域内(IND)意图类别的先验知识，帮助新意图的聚类。因此相关方法都遵循一个两阶段框架：IND预训练和OOD聚类。其中的关键挑战在于如何将IND先验知识迁移到OOD聚类上。之前的方法普遍存在一个问题，将IND预训练过程当作分类任务，采用一个交叉熵分类损失，模型学习到如何分类IND样本，但是下游我们需要对OOD聚类。两个阶段不同的学习目标使得存在一个天然的语义鸿沟，使得IND到OOD的知识迁移变得困难。此外，我们观察到之前的方法只迁移BERT输出的一个共享意图表征，考虑到表征具有高度耦合性，这样一个表征可能不利于OOD聚类。例如，在IND预训练的编码器中存在实例级(instance-level)和聚类级(class-level)的知识，解耦不同级别的知识有助于更好地知识迁移。为了解决这样的问题，我们建立了一个统一的多头对比学习框架，并在此基础上提出了一个新颖的解耦知识迁移方法(DKT)，以便迁移解耦IND意图知识用于OOD聚类。我们意在弥合IND预训练和OOD聚类两个阶段的语义鸿沟。两个基准数据集的实验和分析显示了我们方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Equal Contribution&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Corresponding Author&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Measure and Improve Robustness in NLP Models: A Survey</title>
      <link>https://pris-nlp.github.io/en/post/211227wzc/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://pris-nlp.github.io/en/post/211227wzc/</guid>
      <description>&lt;!-- 如果你想外链到其他博客分享论文，插入超链接即可
[一个帅哥的论文分享](https://helicqin.github.io/2021/08/08/Modeling%20Fine-Grained%20Entity%20Types%20with%20Box%20Embeddings/) --&gt;
&lt;!-- 当然你也可以直接在这里写博客，像下面这样 --&gt;
&lt;p&gt;本文是一片关于NLP模型鲁棒性的综述，统一地介绍了如何定义、衡量和提升NLP模型的鲁棒性。&lt;/p&gt;
&lt;h2 id=&#34;nlp模型鲁棒性的定义&#34;&gt;NLP模型鲁棒性的定义&lt;/h2&gt;
&lt;p&gt;模型在$(x, y) \sim \mathcal{D}$上训练，在$(x&#39;, y&#39;)\sim \mathcal{D&#39;} \ne \mathcal{D}$
上测试，可以用模型在$\mathcal{D&#39;}$上的性能（如准确率）衡量模型的鲁棒性。&lt;/p&gt;
&lt;p&gt;可以粗略地将现有的模型鲁棒性的文献分为两类：$\mathcal{D&#39;}$是对输入合成扰动，或者
$\mathcal{D&#39;}$是自然发生的分布转移。&lt;/p&gt;
&lt;h3 id=&#34;对对抗攻击的鲁棒性&#34;&gt;对对抗攻击的鲁棒性&lt;/h3&gt;
&lt;p&gt;对抗攻击是指故意精心制造噪声来欺骗模型做出错误的预测，之前在CV领域被广泛探索，
后来扩展到NLP领域。对抗样本的生成主要建立在这样一个观察之上，即我们可以生成对人类有意义的样本(例如，通过用人类察觉不到的变化干扰样本)，同时改变对该样本的模型预测。
对抗攻击主要建立在人类可以理解大量同义词或者忽略字母的确切顺序，但机器不能。&lt;/p&gt;
&lt;p&gt;现在大多数CV研究都做了一个相对简单的假设，即在$x$上加有界摄动得到的$x&#39;$的金标应该保持不变，
即$y&#39;=y$，模型的鲁棒行为应该是$f(x&#39;)=f(x)$。其中的摄动可以是token和字符的交换，释义，
不改变语义的对抗规则，或者添加干扰因素。&lt;/p&gt;
&lt;p&gt;然而，这个标签不变的假设可能并不总是成立的，有人研究了几种现有的文本扰动技术，但发现
一大部分扰动样本都改变了标签（尽管是在保留标签的假设下）或者结果的标签在人类标注者中
存在高度分歧。&lt;/p&gt;
&lt;p&gt;还有一个相似的概念是语义保留，是指$(x, x&#39;)$之间的语义是不变的，而上面的标签保留是指
$(y, y&#39;)$是不变的。&lt;/p&gt;
&lt;h3 id=&#34;对分布转移的鲁棒性&#34;&gt;对分布转移的鲁棒性&lt;/h3&gt;
&lt;p&gt;现有的鲁棒性定义更接近域泛化或OOD泛化的概念，其中测试集（不管有无标签）都是在训练的时候
不可获取的。
在NLP背景下，对自然分布转移的鲁棒性也意味着模型的性能不会因为语法错误、方言、说话者和
语言的差异或者为同一任务不同领域新收集的数据集而降低。&lt;/p&gt;
&lt;p&gt;另一个密切相关的研究方向是公平性，例如，在指代消解、职业分类、神经机器翻译等任务中观察到了性别刻板印象或偏差。&lt;/p&gt;
&lt;h3 id=&#34;联系和共同主题&#34;&gt;联系和共同主题&lt;/h3&gt;
&lt;p&gt;合成
上述两个分类都可以归为一个框架中，即$\mathcal{D&#39;}$代表合成分布转移（通过对抗攻击）或自然分布转移。
两者的联系仍有待探索。在CV领域，有研究表面对合成分布转移的鲁棒性可能对自然分布转移鲁棒性贡献
很少甚至没有贡献。&lt;/p&gt;
&lt;p&gt;为了更好地理解模型为什么缺乏鲁棒性，一些现有的工作认为这是因为模型有时利用虚假的特征和标签之间的
关系，而非真正的关系。其中虚假的特征通常定义为并不真正影响任务标签的特征。它们和任务标签有联系，但是不能转移到更加有挑战性的测试条件或OOD数据。一些其他的工作将其定义为适用于大多数情况但不适用于一般情况的规则。这些虚假的关系有时被称为数据集偏差或群体转移。此外，有证据表明，控制模型在虚假特征下的学习将提高模型在分布转移中的性能。还有学者讨论了对抗鲁棒性和伪特征学习之间的联系。还有人通过将模型在分布转移或对抗性攻击中缺乏鲁棒性的原因归因于模型对虚假特征的学习，提出了连接这些领域的理论性的讨论。&lt;/p&gt;
&lt;p&gt;此外，在某些应用中，模型的鲁棒性也可以与模型的不稳定性或者模型的不确定度估计很差联系起来。
对于此，有人提出了贝叶斯方法、基于dropout和基于组装的实现方法。最近，Ovadia等人已经证明，模型的不确定性估计可能在分配转移下显著降低，并呼吁应当通过对OOD数据给出更低的不确定性估计，确保
模型“知道它什么时候不知道”。&lt;/p&gt;
&lt;h2 id=&#34;识别非鲁棒&#34;&gt;识别非鲁棒&lt;/h2&gt;
&lt;p&gt;随着鲁棒性在自然语言处理文献中得到越来越多的关注，各行各业都提出了识别自然语言处理模型鲁棒性失效的方法。现有工作可以根据故障的识别方式大致分类，其中很大一部分工作依赖于人类先验和对现有NLP模型的错误分析，其他一些工作线采用基于模型的方法。为了更准确地度量自然语言处理模型的鲁棒性，通常将识别出的鲁棒性失效模式组织成具有挑战性/对抗性的基准数据集。表1展示了用于识别模型鲁棒性失效的常用扰动类型（数据集），在表2中，我们总结了每个NLP任务的常见鲁棒性基准（benchmark）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://s2.loli.net/2021/12/27/vwJmq2xBXTMHcfO.png&#34; alt=&#34;fig&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;人类先验和错误分析驱动的&#34;&gt;人类先验和错误分析驱动的&lt;/h3&gt;
&lt;p&gt;按任务分，包括NLI（Natural Language Inference），QA和神经机器翻译。&lt;/p&gt;
&lt;h4 id=&#34;nli&#34;&gt;NLI&lt;/h4&gt;
&lt;p&gt;Naik等人抽样错误分类的例子，并分析其潜在的错误来源，然后将其归类为常见错误原因的类型。这些错误类型将作为构建压力测试集的基础，以进一步评估NLI模型是否具有做出真实推理决策的能力，还是仅仅依赖于复杂的模式匹配。Gururangan等人发现，目前的NLI模型很可能仅依靠假设来识别标签，而Poliak等人提供了类似的补充，即我们采用仅假设的模型可以优于一组强基线。&lt;/p&gt;
&lt;h4 id=&#34;qa&#34;&gt;QA&lt;/h4&gt;
&lt;p&gt;有人提出通过在段落末尾串联一个敌对的干扰句来生成敌对的QA例子。Miller等人为斯坦福问答数据集(SQuAD)构建了四个新的测试集，并发现大多数问答系统未能推广到这一新的数据。他们也希望对自然分布转移进行新的评估指标。&lt;/p&gt;
&lt;h4 id=&#34;机器翻译&#34;&gt;机器翻译&lt;/h4&gt;
&lt;p&gt;Belinkov和Bisk发现，当面对嘈杂数据时，基于字符的神经机器翻译(NMT)模型是脆弱的，很容易不稳定，其中噪音(例如，打字、拼写错误等)是使用可能的词汇替换合成的。使用包含人工引入语法错误的句子或随机合成噪音的增强训练数据可以使系统对这种虚假模式更加稳健。另一方面，有人展示了另一种方法，通过限制字符的输入空间，使模型有可能感知数据输入错误和拼写错误。&lt;/p&gt;
&lt;h3 id=&#34;基于模型的&#34;&gt;基于模型的&lt;/h3&gt;
&lt;p&gt;这种方法有的是任务不确定的，有的是输入不可知的。
这种方法通过训练一个额外的模型来捕获偏差。例如，在视觉问题回答中，Clark等人训练一个朴素模型来预测基于问题的原型答案，而不考虑上下文;Utama等人提出学习一个仅使用数据集偏差相关特征的有偏模型。此外，Culotta的目标是通过训练分类器来识别模型中的捷径，从而从人类标注的例子中更好地区分虚假的相关性和真实的相关性。&lt;/p&gt;
&lt;h2 id=&#34;提升模型鲁棒性&#34;&gt;提升模型鲁棒性&lt;/h2&gt;
&lt;p&gt;根据人工干预的位置和方式，这些方法可以分为数据驱动的、基于模型和训练方案的、基于归纳先验和最后的因果干预。&lt;/p&gt;
&lt;h3 id=&#34;数据驱动数据增强&#34;&gt;数据驱动（数据增强）&lt;/h3&gt;
&lt;p&gt;如Mixup, MixText, CutOut, AugMix, HiddenCut。这类缓解方法是在数据层面上操作的，往往很难解释如何以及为什么起作用。&lt;/p&gt;
&lt;h3 id=&#34;基于模型和训练策略&#34;&gt;基于模型和训练策略&lt;/h3&gt;
&lt;h4 id=&#34;预训练&#34;&gt;预训练&lt;/h4&gt;
&lt;p&gt;最近的研究表明，预训练是提高NLP模型非分布鲁棒性的有效方法，这可能是因为其自我监督的目标，以及使用了大量不同的训练前数据，这些数据鼓励从少量的测试样本中归纳出一般化的结果，从而抵消了虚假的相关性。有研究显示一些其他因素也可以促进稳健的准确性，包括更大的模型尺寸、更多的微调数据和更长的微调。Taori等人在视觉领域也进行了类似的观察，其中作者发现，与现有文献提出的各种鲁棒性干预相比，使用更大、更多样化的数据集的训练在多个情况下提供了更好的鲁棒性。&lt;/p&gt;
&lt;h4 id=&#34;更好地利用少数群体的样本训练&#34;&gt;更好地利用少数群体的样本训练&lt;/h4&gt;
&lt;p&gt;还有一些工作建议通过更好地使用少数例子来简化模型，例如，在训练分布中代表性不足的例子，或更难学习的例子。例如，Yaghoobzadeh等人提出，首先根据全部数据对模型进行微调，然后只对少数例子进行微调。一般来说，强调样本子集的训练策略对模型来说特别难学习，有时也被称为DRO（distributional robust optimization，分布式鲁棒优化）组。DRO的扩展主要是讨论如何识别被认为是少数样本。例如，Nam等人通过强调模型的早期决策来训练另一个模型;Lahoti等人也使用另一个模型来识别对主模型具有挑战性的样本;Liu等人提出通过对在第一次训练时损失较大的少数例子增加权重，对模型进行第二次训练。&lt;/p&gt;
&lt;h3 id=&#34;基于归纳的实现方法&#34;&gt;基于归纳的实现方法&lt;/h3&gt;
&lt;p&gt;另一个思路是引入归纳偏差(即正则化假设空间)，迫使模型丢弃一些虚假的特征。这与基于人先验的识别方法密切相关，因为这些人的先验知识通常可以用额外的正则化器来重新制定训练目标。为了实现这一目标，通常需要首先构造一个侧组件来通知主模型有偏差的特征，然后根据侧组件来正则化主模型。这个侧组件的构造通常依赖于失调特征是什么的先验知识。然后，可以建立相应的方法来应对特征。类似地，Clark等人提出用一个显式捕获偏差的模型进行集成，其中主模型与这个仅偏差（bias-only）模型一起训练，这样主模型就不被鼓励使用偏差。最近的工作表明，通过更好地校准仅偏差模型，基于集成的方法可以进一步改进。&lt;/p&gt;
&lt;p&gt;总之，这种方法大概是在不同的领域/分布中训练小的经验损失，以迫使模型对特定领域的虚假特征不变。&lt;/p&gt;
&lt;h3 id=&#34;干预因果关系&#34;&gt;干预因果关系&lt;/h3&gt;
&lt;p&gt;Srivastava利用人类对因果关系的常识知识，以潜在的未测量变量来增加训练样本，并提出了一种基于DRO的方法，以使模型对分布转移具有鲁棒性。Veitch等人提出学习依赖于数据因果结构的估计反事实不变量预测，并表明它可以帮助减少文本分类中的虚假相关性。&lt;/p&gt;
&lt;h3 id=&#34;提升鲁棒性策略的联系&#34;&gt;提升鲁棒性策略的联系&lt;/h3&gt;
&lt;p&gt;大体可分为3类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;利用大量数据预训练模型&lt;/li&gt;
&lt;li&gt;学习跨领域/环境的不变表示或预测&lt;/li&gt;
&lt;li&gt;基于具体的虚假/偏见模式的数据&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有趣的是，统计研究表明，许多缓解方法都有相同的鲁棒机器学习泛化误差界。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
