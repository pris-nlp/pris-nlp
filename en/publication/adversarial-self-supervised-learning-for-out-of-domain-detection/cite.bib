@inproceedings{zeng-etal-2021-adversarial,
    title = "Adversarial Self-Supervised Learning for Out-of-Domain Detection",
    author = "Zeng, Zhiyuan  and
      He, Keqing  and
      Yan, Yuanmeng  and
      Xu, Hong  and
      Xu, Weiran",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.447",
    doi = "10.18653/v1/2021.naacl-main.447",
    pages = "5631--5639",
    abstract = "Detecting out-of-domain (OOD) intents is crucial for the deployed task-oriented dialogue system. Previous unsupervised OOD detection methods only extract discriminative features of different in-domain intents while supervised counterparts can directly distinguish OOD and in-domain intents but require extensive labeled OOD data. To combine the benefits of both types, we propose a self-supervised contrastive learning framework to model discriminative semantic features of both in-domain intents and OOD intents from unlabeled data. Besides, we introduce an adversarial augmentation neural module to improve the efficiency and robustness of contrastive learning. Experiments on two public benchmark datasets show that our method can consistently outperform the baselines with a statistically significant margin.",
}