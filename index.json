[{"authors":["WeiranXu"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"f7f1828bc4d3f77885779338384d5198","permalink":"https://pris-nlp.github.io/author/weiran-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/weiran-xu/","section":"authors","summary":"","tags":null,"title":"Weiran Xu","type":"authors"},{"authors":["YuanmengYan"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"fada719e3feff979780c87df53610f4a","permalink":"https://pris-nlp.github.io/author/yuanmeng-yan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuanmeng-yan/","section":"authors","summary":"","tags":null,"title":"Yuanmeng Yan","type":"authors"},{"authors":["DaichiGuo"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da5ab810d8039861073d5dc563cefc8f","permalink":"https://pris-nlp.github.io/author/daichi-guo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/daichi-guo/","section":"authors","summary":"","tags":null,"title":"Daichi Guo","type":"authors"},{"authors":["QianyuCao"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e9b3152c58f76bd04c003e496373a415","permalink":"https://pris-nlp.github.io/author/qianyu-cao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/qianyu-cao/","section":"authors","summary":"","tags":null,"title":"Qianyu Cao","type":"authors"},{"authors":["LiwenWang"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"adada2facae11e3f486b44e919b8db2a","permalink":"https://pris-nlp.github.io/author/liwen-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/liwen-wang/","section":"authors","summary":"","tags":null,"title":"Liwen Wang","type":"authors"},{"authors":["XuefengLi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"9d7c1c0c900bc56efb9e418a468b6172","permalink":"https://pris-nlp.github.io/author/xuefeng-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xuefeng-li/","section":"authors","summary":"","tags":null,"title":"Xuefeng Li","type":"authors"},{"authors":["FujiaZheng"],"categories":null,"content":"","date":1600523751,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"953924eb0a5f7b1fc0a5c25f4c4f989c","permalink":"https://pris-nlp.github.io/author/fujia-zheng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fujia-zheng/","section":"authors","summary":"","tags":null,"title":"Fujia Zheng","type":"authors"},{"authors":["YananWu"],"categories":null,"content":"","date":1600523751,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"cc8ce7c377a7104416cd440a54027525","permalink":"https://pris-nlp.github.io/author/yanan-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yanan-wu/","section":"authors","summary":"","tags":null,"title":"Yanan Wu","type":"authors"},{"authors":["ChenZeng"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f967eaa9aadcd6a0176d7f81f87f031e","permalink":"https://pris-nlp.github.io/author/chen-zeng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chen-zeng/","section":"authors","summary":"","tags":null,"title":"Chen Zeng","type":"authors"},{"authors":["GuantingDong"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"eb44dbee8694f917cc30af1ed6e380a6","permalink":"https://pris-nlp.github.io/author/guanting-dong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/guanting-dong/","section":"authors","summary":"","tags":null,"title":"Guanting Dong","type":"authors"},{"authors":["HaoLei"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ca6b7927c276a8d431611c5bb76f3334","permalink":"https://pris-nlp.github.io/author/hao-lei/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hao-lei/","section":"authors","summary":"","tags":null,"title":"Hao Lei","type":"authors"},{"authors":["Qixiang Gao"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"15a8a8196173924896cf2b574ccdffd8","permalink":"https://pris-nlp.github.io/author/qixiang-gao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/qixiang-gao/","section":"authors","summary":"","tags":null,"title":"Qixiang Gao","type":"authors"},{"authors":["RuotongGeng"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a7dbd44e4cdf66c3e4433fa1e6f3afe0","permalink":"https://pris-nlp.github.io/author/ruotong-geng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ruotong-geng/","section":"authors","summary":"","tags":null,"title":"Ruotong Geng","type":"authors"},{"authors":["YutaoMu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3f2a530a96fc0a7015690a0de3bf8fef","permalink":"https://pris-nlp.github.io/author/yutao-mu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yutao-mu/","section":"authors","summary":"","tags":null,"title":"Yutao Mu","type":"authors"},{"authors":["WeihaoZeng"],"categories":null,"content":"","date":1600523751,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1600523752,"objectID":"2b545b98f6c5cfccc2d06f5586ef14bd","permalink":"https://pris-nlp.github.io/author/weihao-zeng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/weihao-zeng/","section":"authors","summary":"","tags":null,"title":"Weihao Zeng","type":"authors"},{"authors":["HuaXu"],"categories":[],"content":"","date":1409557409,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409557409,"objectID":"aa585aa49362c42e9f2830d01bcf8f37","permalink":"https://pris-nlp.github.io/textbook/datamining-methodandapplication/","publishdate":"2014-09-01T15:43:29+08:00","relpermalink":"/textbook/datamining-methodandapplication/","section":"textbook","summary":"Mainly based on the teaching practice and accumulation of the Data Mining Methods and Applications course set up by Tsinghua University, referring to the teaching system of relevant courses of famous foreign universities in recent years, systematically introducing the basic concepts and basic principles of data mining; combining some typical applications Examples show general patterns and ideas for solving problems with data mining thinking methods.","tags":["Data Mining"],"title":"Data Mining: Methodology and Applications","type":"textbook"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"dff53f196c9fa8e89f6523d449108d7a","permalink":"https://pris-nlp.github.io/patent/%E5%9F%BA%E4%BA%8E%E7%96%91%E9%97%AE%E8%AF%8D%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95%E5%8F%8A%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%9F%BA%E4%BA%8E%E7%96%91%E9%97%AE%E8%AF%8D%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95%E5%8F%8A%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"基于疑问词分类器的神经网络问题生成方法及生成系统","type":"patent"},{"authors":["HuaXu"],"categories":[],"content":"","date":1201851809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1201851809,"objectID":"2bfeedb392926ea9bc043feb5ad0e8ed","permalink":"https://pris-nlp.github.io/monograph/petrinettheoryandapplications/","publishdate":"2008-02-01T15:43:29+08:00","relpermalink":"/monograph/petrinettheoryandapplications/","section":"monograph","summary":"Chapter 12: Timed Hierarchical Object-oriented Petri Net, I-Tech Education and Publishing, Vienna, Austria, 2008, pp.253-280, ISNN:978-3-902613-12-7 (Hua Hu participated in the writing, published in February 2008)","tags":[],"title":"Petri Net: Theory and Applications","type":"monograph"},{"authors":["HuaXu"],"categories":[],"content":"","date":1504251809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504251809,"objectID":"cb3a9f5f79958edae4960ecccacd7726","permalink":"https://pris-nlp.github.io/textbook/datamining-methodandapplication-case/","publishdate":"2017-09-01T15:43:29+08:00","relpermalink":"/textbook/datamining-methodandapplication-case/","section":"textbook","summary":"Mainly based on the teaching practice and accumulation of the Data Mining Methods and Applications course set up by Tsinghua University, referring to the teaching system of relevant courses of famous foreign universities in recent years, systematically introducing the basic concepts and basic principles of data mining; combining some typical applications Examples show general patterns and ideas for solving problems with data mining thinking methods.","tags":["Data Mining"],"title":"Data Mining: Methods and Applications - Application Cases","type":"textbook"},{"authors":["Weiran Xu","Yanan Wu","Yuanmeng Yan"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"290198b503d62d1657204867f47da26e","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%BB%93%E6%9E%84%E5%8C%96%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%E6%8F%8F%E8%BF%B0%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%BB%93%E6%9E%84%E5%8C%96%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%E6%8F%8F%E8%BF%B0%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"一种基于结构化用户属性描述的个性化任务型对话系统","type":"patent"},{"authors":["HuaXu"],"categories":[],"content":"","date":1470037409,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470037409,"objectID":"f3c91f32b83aaa1a5de73ea397ed32b4","permalink":"https://pris-nlp.github.io/textbook/bigdatatechnologyandindustryapplications/","publishdate":"2016-08-01T15:43:29+08:00","relpermalink":"/textbook/bigdatatechnologyandindustryapplications/","section":"textbook","summary":"How to define big data? How to apply big data? What is big data thinking? How to learn big data? How to build a big data platform? How to apply big data in the industry? This series of problems are very confusing problems in the current era of big data boom. Big Data Technology and Industry Application faces these questions directly, answers the above questions from the perspective of practitioners, and hopes to provide some help to beginners in the big data industry.","tags":["Big Data"],"title":"Big Data Technology and Industry Applications","type":"textbook"},{"authors":["HuaXu"],"categories":[],"content":"","date":1454312609,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454312609,"objectID":"4949ddee0a08346cb8809beaaa742b23","permalink":"https://pris-nlp.github.io/monograph/sentimentanalysisandontologyengineering/","publishdate":"2016-02-01T15:43:29+08:00","relpermalink":"/monograph/sentimentanalysisandontologyengineering/","section":"monograph","summary":"Chapter 10: Chinese Micro-Blog Emotion Classification by Exploiting Linguistic Features and SVMperf ), Springer International Publishing, 2016, pp. 221-236, ISNN:978-3-319-30317-8 (Hua Hu participated in the writing, published in February 2016)","tags":[],"title":"Sentiment Analysis and Ontology Engineering","type":"monograph"},{"authors":["Weiran Xu","Yuanmeng Yan","Yanan Wu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"5001708f0a28902a5ce679b5ab56b8ec","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%A5%E8%AF%86%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%98%93%E9%85%8D%E7%BD%AE%E4%BB%BB%E5%8A%A1%E5%AF%BC%E5%90%91%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%A5%E8%AF%86%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%98%93%E9%85%8D%E7%BD%AE%E4%BB%BB%E5%8A%A1%E5%AF%BC%E5%90%91%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"一种知识驱动的易配置任务导向型对话管理方法与系统","type":"patent"},{"authors":["HuaXu"],"categories":[],"content":"","date":1201851809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1201851809,"objectID":"2c5c9a0907335dbc37fce7e6ceebe45b","permalink":"https://pris-nlp.github.io/monograph/recentadvancesinmulti-robotsystems/","publishdate":"2008-02-01T15:43:29+08:00","relpermalink":"/monograph/recentadvancesinmulti-robotsystems/","section":"monograph","summary":"Chapter 13: A Novel Modeling Method for Cooperative Multi-robot Systems Using Fuzzy Timed Agent Based Petri Nets ), I-Tech Education and Publishing, Vienna, Austria, 2008, pp.249-262, ISNN:978-3-902613-24-0 (Hua Hu participated in the writing, published in February 2008)","tags":[],"title":"Recent Advances in Multi-robot Systems","type":"monograph"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"533212db21ceb7d036aa5b3495271654","permalink":"https://pris-nlp.github.io/patent/%E5%BB%BA%E6%A8%A1%E5%AF%B9%E8%AF%9D%E8%BD%AE%E6%AC%A1%E4%BF%A1%E6%81%AF%E7%9A%84%E6%A3%80%E7%B4%A2%E5%BC%8F%E9%97%B2%E8%81%8A%E5%AF%B9%E8%AF%9D%E6%89%93%E5%88%86%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%BB%BA%E6%A8%A1%E5%AF%B9%E8%AF%9D%E8%BD%AE%E6%AC%A1%E4%BF%A1%E6%81%AF%E7%9A%84%E6%A3%80%E7%B4%A2%E5%BC%8F%E9%97%B2%E8%81%8A%E5%AF%B9%E8%AF%9D%E6%89%93%E5%88%86%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"建模对话轮次信息的检索式闲聊对话打分方法","type":"patent"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1107243809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1107243809,"objectID":"30837e0151d041aff588987056d3a925","permalink":"https://pris-nlp.github.io/textbook/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8/","publishdate":"2005-02-01T15:43:29+08:00","relpermalink":"/textbook/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8/","section":"textbook","summary":"The first four chapters of \"Computational Geometry: Algorithms and Applications (3rd Edition)\" discuss geometric algorithms, including geometric intersection, triangulation, linear programming, etc. The random algorithm involved is also \"Computational Geometry: Algorithms and Applications (Third Edition)\" a distinctive feature. Chapters 5 to 10 introduce a variety of geometric structures. Chapters 11 to 16 continue to discuss several geometric algorithms and their data structures based on practical problems, they are also further deepening of the content of the first 10 chapters. \"Computational Geometry: Algorithms and Applications (3rd Edition)\" is not only comprehensive in content, but also closely related to practical applications, with prominent points. It has in-depth explanations, and each chapter has \"notes and comments\" and \"exercises\" for the convenience of readers A deeper understanding has been used as teaching materials by many universities around the world.","tags":[],"title":"Computational Geometry: Algorithms and Applications","type":"textbook"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"8ca7a04f158ea4a16f469a89f85c0315","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B7%E5%8F%A0%E4%BF%A1%E5%8F%B7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%B7%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%88%A4%E5%88%AB%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B7%E5%8F%A0%E4%BF%A1%E5%8F%B7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%B7%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%88%A4%E5%88%AB%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"一种基于混叠信号深度学习的跳频信号判别方法","type":"patent"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1138779809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1138779809,"objectID":"c70ac8a450da7476c774fb168d54bc54","permalink":"https://pris-nlp.github.io/textbook/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95java%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0/","publishdate":"2006-02-01T15:43:29+08:00","relpermalink":"/textbook/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95java%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0/","section":"textbook","summary":"This book fully demonstrates the application of object-oriented technology in modern data structure theory, generally using abstraction, encapsulation, and inheritance technologies. This book not only introduces the basic data structure, but also introduces the application, implementation and analysis methods of the algorithm in combination with specific problems. The book also unifies various graph algorithms through the traversal algorithm framework and implements it based on the traversal algorithm template. Unique among similar textbooks.","tags":[],"title":"Data Structures and Algorithms (Java Description)","type":"textbook"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1075621409,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1075621409,"objectID":"7dedbd79296664918c876247a7356cba","permalink":"https://pris-nlp.github.io/monograph/%E8%B4%A8%E9%87%8F%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86/","publishdate":"2004-02-01T15:43:29+08:00","relpermalink":"/monograph/%E8%B4%A8%E9%87%8F%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86/","section":"monograph","summary":"Tsinghua University Press (Jun. 2004) ISBN: 7-302-08298-7 （Original Work：Gerald M. Weinberg, Quality Software Management:Systems Thinking ,Dorset House (Sep. 1991), ISBN: 0-932-63322-6.）","tags":[],"title":"Quality Software Management (Volume 1)-System Thinking","type":"monograph"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1044085409,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1044085409,"objectID":"edca37e22f48ff86ab5a6e634b5b3a8a","permalink":"https://pris-nlp.github.io/monograph/%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%BF%83%E7%90%86%E5%AD%A6%E9%93%B6%E5%B9%B4%E7%BA%AA%E5%BF%B5%E7%89%88/","publishdate":"2003-02-01T15:43:29+08:00","relpermalink":"/monograph/%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%BF%83%E7%90%86%E5%AD%A6%E9%93%B6%E5%B9%B4%E7%BA%AA%E5%BF%B5%E7%89%88/","section":"monograph","summary":"Tsinghua University Press (Sep. 2003) ISBN: 7-302-07026-1 （Original Work：Gerald M. Weinberg, The Psychology of Computer Programming: Silver Anniversary Edition, Dorset House (Sep. 1998), ISBN: 0-932-63342-0.）","tags":[],"title":"The Psychology of Computer Programming","type":"monograph"},{"authors":["HuaXu"],"categories":[],"content":"","date":1602301409,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602301409,"objectID":"d9809ef0bb72c0fdeb8f093635124ba3","permalink":"https://pris-nlp.github.io/textbook/%E6%96%87%E6%9C%AC%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/","publishdate":"2020-10-10T11:43:29+08:00","relpermalink":"/textbook/%E6%96%87%E6%9C%AC%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/","section":"textbook","summary":"This book explains the text big data sentiment analysis technology from multiple dimensions. The content covers natural language processing and text emotion and sentiment methods, as well as sentiment analysis of Weibo texts and their incentives, position analysis of topic-oriented comments, texts Representation method and its application in emotion classification. The book is organized in a modular manner, with strong theoretical and clear organization. The author team implemented the main methods in the book with a serious and rigorous scientific attitude, and described the effects of various methods. This book can provide help for the study and scientific research work of college students in related majors (such as computer science and technology, software engineering, etc.). It also has a higher reference value for engineering and technical personnel engaged in text mining and natural language processing.","tags":[],"title":"Big Data Sentiment Analysis in Text","type":"textbook"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"9b07acc9b039169e280ab7a2cbc3d5f1","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"一种基于嵌入式表示的自适应中文分词方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"c9382e1521faef0f1c470943165b62e9","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%A4%9A%E7%B2%92%E5%BA%A6%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%A4%9A%E7%B2%92%E5%BA%A6%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"一种基于隐多粒度局部特征的中文分词方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"8335423f963cfa0e1f8095291c070504","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E7%9A%84%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%92%8C%E8%AE%BE%E5%A4%87/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E7%9A%84%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%92%8C%E8%AE%BE%E5%A4%87/","section":"patent","summary":"","tags":[],"title":"一种短信的识别方法和设备","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"d64632bbdea2aae7e69200d4fc20b3ab","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4%E7%9A%84%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4%E7%9A%84%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE/","section":"patent","summary":"","tags":[],"title":"一种短信过滤的方法和装置","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"5d6d3881631418d9d60339c26575e438","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE/","section":"patent","summary":"","tags":[],"title":"一种短信过滤方法和装置","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"5e905ec1fdafe8f5121c2211943507e9","permalink":"https://pris-nlp.github.io/patent/%E9%98%B2%E5%81%87%E6%AD%BB%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E9%98%B2%E5%81%87%E6%AD%BB%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"防假死爬虫系统的构建方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"ed911f5b24e54d4ff36a511e61e1eee4","permalink":"https://pris-nlp.github.io/patent/%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"分布式爬虫集群系统","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"a0bce571fdebdebd57bd7324fcd6a4d2","permalink":"https://pris-nlp.github.io/patent/%E5%B8%83%E5%91%8A%E6%A0%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%B8%83%E5%91%8A%E6%A0%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"布告栏搜索引擎的爬虫系统构建方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"5b0c68e2014051e68cfd76ee3adcbfe0","permalink":"https://pris-nlp.github.io/patent/%E5%B9%B6%E8%A1%8C%E5%BC%8F%E5%85%B3%E8%81%94%E5%B8%83%E5%91%8A%E6%A0%8F%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%B9%B6%E8%A1%8C%E5%BC%8F%E5%85%B3%E8%81%94%E5%B8%83%E5%91%8A%E6%A0%8F%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"并行式关联布告栏爬虫系统","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"33a28ddc2ab4c3abd236925d2a51602e","permalink":"https://pris-nlp.github.io/patent/%E8%87%AA%E5%8A%A8%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E8%87%AA%E5%8A%A8%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"自动动态更新论坛爬虫系统的构建方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"beb355b6e727e985c23a61c317c7df5a","permalink":"https://pris-nlp.github.io/patent/%E5%90%8C%E8%AF%9D%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%B7%9F%E8%B8%AA%E5%BC%8F%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%90%8C%E8%AF%9D%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%B7%9F%E8%B8%AA%E5%BC%8F%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"同话题定位跟踪式论坛爬虫系统","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"d95c2984046fab93affb647ddd435e14","permalink":"https://pris-nlp.github.io/patent/%E5%86%85%E9%83%A8%E7%BD%91%E5%8F%AF%E5%AE%9A%E5%88%B6%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%86%85%E9%83%A8%E7%BD%91%E5%8F%AF%E5%AE%9A%E5%88%B6%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"内部网可定制爬虫系统构建方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"3d670f3ae8eb0472cae9fc7ab9698c31","permalink":"https://pris-nlp.github.io/patent/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%86%85%E9%83%A8%E7%BD%91%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%86%85%E9%83%A8%E7%BD%91%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"多线程断点续传可定制内部网爬虫系统","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"727b3252c03b39978223f9b4f00c0a0f","permalink":"https://pris-nlp.github.io/patent/%E5%9F%BA%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E6%96%87%E5%AD%97%E5%AD%97%E4%BD%93%E5%88%A4%E6%96%AD%E8%AE%BE%E5%A4%87%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%9F%BA%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E6%96%87%E5%AD%97%E5%AD%97%E4%BD%93%E5%88%A4%E6%96%AD%E8%AE%BE%E5%A4%87%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"基于贝叶斯分类器的文字字体判断设备及其方法","type":"patent"},{"authors":["Weiran Xu"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225266209,"objectID":"dcb5184244faf499a588648530a2c9c3","permalink":"https://pris-nlp.github.io/patent/%E7%94%A8%E4%BA%8E%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E8%87%AA%E5%8A%A8%E6%8C%91%E9%80%89%E8%A3%85%E7%BD%AE%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E7%94%A8%E4%BA%8E%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E8%87%AA%E5%8A%A8%E6%8C%91%E9%80%89%E8%A3%85%E7%BD%AE%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"用于文字识别的训练样本自动挑选装置及其方法","type":"patent"},{"authors":["Liwen Wang","Xuefeng Li","JiachiLiu","KeqingHe","Yuanmeng Yan","Weiran Xu"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"385842321aef2a5899368efefd05b945","permalink":"https://pris-nlp.github.io/publication/bridge-to-target-domain-by-prototypical-contrastive-learning-and-label-confusion-re-explore-zero-shot-learning-for-slot-filling/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/bridge-to-target-domain-by-prototypical-contrastive-learning-and-label-confusion-re-explore-zero-shot-learning-for-slot-filling/","section":"publication","summary":"Zero-shot cross-domain slot filling alleviates the data dependence in the case of data scarcity in the target domain, which has aroused extensive research. However, as most of the existing methods do not achieve effective knowledge transfer to the target domain, they just fit the distribution of the seen slot and show poor performance on unseen slot in the target domain. To solve this, we propose a novel approach based on prototypical contrastive learning with a dynamic label confusion strategy for zero-shot slot filling. The prototypical contrastive learning aims to reconstruct the semantic constraints of labels, and we introduce the label confusion strategy to establish the label dependence between the source domains and the target domain on-the-fly. Experimental results show that our model achieves significant improvement on the unseen slots, while also set new state-of-the-arts on slot filling task.","tags":["\"Slot filling\""],"title":"Bridge to Target Domain by Prototypical Contrastive Learning and Label Confusion Re-explore Zero-Shot Learning for Slot Filling","type":"publication"},{"authors":["HongXu","KeqingHe","Yuanmeng Yan","SihongLiu","ZijunLiu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"c6801eecfd9d1668cc7b342e6d71f923","permalink":"https://pris-nlp.github.io/publication/a-deep-generative-distance-based-classifier-for-out-of-domain-detection-with-mahalanobis-space/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/a-deep-generative-distance-based-classifier-for-out-of-domain-detection-with-mahalanobis-space/","section":"publication","summary":"Zero-shot slot filling has widely arisen to cope with data scarcity in target domains. However, previous approaches often ignore constraints between slot value representation and related slot description representation in the latent space and lack enough model robustness. In this paper, we propose a Contrastive Zero-Shot Learning with Adversarial Attack (CZSL-Adv) method for the cross-domain slot filling. The contrastive loss aims to map slot value contextual representations to the corresponding slot description representations. And we introduce an adversarial attack training strategy to improve model robustness. Experimental results show that our model significantly outperforms state-of-the-art baselines under both zero-shot and few-shot settings.","tags":["\"OOD\"","\"intent detection\""],"title":"A Deep Generative Distance-Based Classifier for Out-of-Domain Detection with Mahalanobis Space","type":"publication"},{"authors":["YuejieLei","Fujia Zheng","Yuanmeng Yan","KeqingHe","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"5a9fadb5279182c5f605d4bb596c178e","permalink":"https://pris-nlp.github.io/publication/a-finer-grain-universal-dialogue-semantic-structures-based-model-for-abstractive-dialogue-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/a-finer-grain-universal-dialogue-semantic-structures-based-model-for-abstractive-dialogue-summarization/","section":"publication","summary":"Although models in abstractive summarization have achieved impressive results on document summarization tasks, their performance on dialogue modeling is much less satisfactory due to the crude and straight methods for dialogue encoding. To address this question, we propose a novel end-to-end Transformer-based model FinDS for abstractive dialogue summarization that leverages Finer-grain universal Dialogue semantic Structures to model dialogue and generates better summaries. Experiments on the SAMsum dataset show that FinDS outperforms various dialogue summarization approaches and achieves new state-of-the-art (SOTA) ROUGE-F results. Finally, we apply FinDS to a more complex scenario, showing the robustness of our model. We will release our source code after blind review.","tags":["\"Dialogue Summarization\""],"title":"A Finer-grain Universal Dialogue Semantic Structures based Model For Abstractive Dialogue Summarization","type":"publication"},{"authors":["KeqingHe","Yuanmeng Yan","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"c477c292e6854b6702d1eb514b4230f7","permalink":"https://pris-nlp.github.io/publication/adversarial-cross-lingual-transfer-learning-for-slot-tagging-of-low-resource-languages/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/adversarial-cross-lingual-transfer-learning-for-slot-tagging-of-low-resource-languages/","section":"publication","summary":"Slot tagging is a key component in a task-oriented dialogue system. Conversational agents need to understand human input by training on large amounts of annotated data. However, most human languages are low-resource and lack annotated training data for slot tagging task. Therefore, we aim to leverage cross-lingual transfer learning from high-resource languages to low-resource ones. In this paper, we propose an adversarial cross-lingual transfer model with multi-level language shared and specific knowledge to improve the slot tagging task of low-resource languages. Our method explicitly separates the model into the language-shared part and language-specific part to transfer language-independent knowledge. To refine shared knowledge in the latent space, we add a language discriminator and employ adversarial training to reinforce feature separation. Besides, we adopt a novel multi-level feature transfer in an incremental and progressive way to acquire multi-granularity shared knowledge. To mitigate the discrepancies between the feature distributions of language specific and shared knowledge, we propose the neural adapters to fuse features from different sources. Experiments show that our proposed model consistently outperforms monolingual baseline with a statistically significant margin up to 2.09%, even higher improvement of 12.21% in the zero-shot setting. Further analysis demonstrates that our method could effectively alleviate data scarcity of low-resource languages.","tags":["\"genetic algorithm\"","\"heterogeneous multiprocessor scheduling\"","\"memetic algorithm\"","\"variable neighborhood search\""],"title":"Adversarial Cross-Lingual Transfer Learning for Slot Tagging of Low-Resource Languages","type":"publication"},{"authors":["ZhiyuanZeng","KeqingHe","Yuanmeng Yan","HongXu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"482f1bd9d93aed37194f0973986c3c4d","permalink":"https://pris-nlp.github.io/publication/adversarial-self-supervised-learning-for-out-of-domain-detection/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/adversarial-self-supervised-learning-for-out-of-domain-detection/","section":"publication","summary":"","tags":["\"OOD\"","\"intent detection\""],"title":"Adversarial Self-Supervised Learning for Out-of-Domain Detection","type":"publication"},{"authors":["Yuanmeng Yan","KeqingHe","HongXu","SihongLiu","FanyuMeng","MinHu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"c75348ca95a9866f3643a784a745dc4a","permalink":"https://pris-nlp.github.io/publication/adversarial-semantic-decoupling-for-recognizing-open-vocabulary-slots/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/adversarial-semantic-decoupling-for-recognizing-open-vocabulary-slots/","section":"publication","summary":"Open-vocabulary slots, such as file name, album name, or schedule title, significantly degrade the performance of neural-based slot filling models since these slots can take on values from a virtually unlimited set and have no semantic restriction nor a length limit. In this paper, we propose a robust adversarial model-agnostic slot filling method that explicitly decouples local semantics inherent in open-vocabulary slot words from the global context. We aim to depart entangled contextual semantics and focus more on the holistic context at the level of the whole sentence. Experiments on two public datasets show that our method consistently outperforms other methods with a statistically significant margin on all the open-vocabulary slots without deteriorating the performance of normal slots.","tags":["\"Slot Filling\""],"title":"Adversarial Semantic Decoupling for Recognizing Open-Vocabulary Slots","type":"publication"},{"authors":["Yuanmeng Yan","RumeiLi","SiruiWang","FuzhengZhang","WeiWu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"d17ed1832a6b7f76a113da7a17518417","permalink":"https://pris-nlp.github.io/publication/consert-a-contrastive-framework-for-self-supervised-sentence-representation-transfer/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/consert-a-contrastive-framework-for-self-supervised-sentence-representation-transfer/","section":"publication","summary":"Learning high-quality sentence representations benefits a wide range of natural language processing tasks. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the native derived sentence representations are proved to be collapsed and thus produce a poor performance on the semantic textual similarity (STS) tasks. In this paper, we present ConSERT, a Contrastive Framework for Self-Supervised SEntence Representation Transfer, that adopts contrastive learning to fine-tune BERT in an unsupervised and effective way. By making use of unlabeled texts, ConSERT solves the collapse issue of BERT-derived sentence representations and make them more applicable for downstream tasks. Experiments on STS datasets demonstrate that ConSERT achieves an 8\\% relative improvement over the previous state-of-the-art, even comparable to the supervised SBERT-NLI. And when further incorporating NLI supervision, we achieve new state-of-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios.","tags":["\"Semantic Textual Similarity\""],"title":"ConSERT A Contrastive Framework for Self-Supervised Sentence Representation Transfer","type":"publication"},{"authors":["KeqingHe","JinchaoZhang","Yuanmeng Yan","Weiran Xu","ChengNiu","JieZhou"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"d2894e19605efc452a5ff05186792a64","permalink":"https://pris-nlp.github.io/publication/contrastive-zero-shot-learning-for-cross-domain-slot-filling-with-adversarial-attack/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/contrastive-zero-shot-learning-for-cross-domain-slot-filling-with-adversarial-attack/","section":"publication","summary":"Zero-shot slot filling has widely arisen to cope with data scarcity in target domains. However, previous approaches often ignore constraints between slot value representation and related slot description representation in the latent space and lack enough model robustness. In this paper, we propose a Contrastive Zero-Shot Learning with Adversarial Attack (CZSL-Adv) method for the cross-domain slot filling. The contrastive loss aims to map slot value contextual representations to the corresponding slot description representations. And we introduce an adversarial attack training strategy to improve model robustness. Experimental results show that our model significantly outperforms state-of-the-art baselines under both zero-shot and few-shot settings.","tags":["\"Slot Filling\""],"title":"Contrastive Zero-Shot Learning for Cross-Domain Slot Filling with Adversarial Attack","type":"publication"},{"authors":["Liwen Wang","Yuanmeng Yan","KeqingHe","Yanan Wu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"b4f0a702fb1f1f8042fe315a418ee6c1","permalink":"https://pris-nlp.github.io/publication/dynamically-disentangling-social-bias-from-task-oriented-representations-with-adversarial-attack/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/dynamically-disentangling-social-bias-from-task-oriented-representations-with-adversarial-attack/","section":"publication","summary":"Representation learning is widely used in NLP for a vast range of tasks. However, representations derived from text corpora often reflect social biases. This phenomenon is pervasive and consistent across different neural models, causing serious concern. Previous methods mostly rely on a pre-specified, user-provided direction or suffer from unstable training. In this paper, we propose an adversarial disentangled debiasing model to dynamically decouple social bias attributes from the intermediate representations trained on the main task. We aim to denoise bias information while training on the downstream task, rather than completely remove social bias and pursue static unbiased representations. Experiments show the effectiveness of our method, both on the effect of debiasing and the main task performance.","tags":["\"Social Bias\"","\"Debias\""],"title":"Dynamically Disentangling Social Bias from Task-Oriented Representations with Adversarial Attack","type":"publication"},{"authors":["KeqingHe","Yuanmeng Yan","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"370fcbc724df4459ab28ea34406f0218","permalink":"https://pris-nlp.github.io/publication/from-context-aware-to-knowledge-aware-boosting-oov-tokens-recognition-in-slot-tagging-with-background-knowledge/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/from-context-aware-to-knowledge-aware-boosting-oov-tokens-recognition-in-slot-tagging-with-background-knowledge/","section":"publication","summary":"Neural-based context-aware models for slot tagging tasks in language understanding have achieved state-of-the-art performance, especially deep contextualized models, such as ELMo, BERT. However, the presence of out-of-vocab (OOV) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-aware slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multi-level graph attention to explicitly reason via lexical relations. We aim to leverage both linguistic regularities covered by deep language models (LM) and high-quality background knowledge derived from curated knowledge bases (KB). Consequently, our model could infer rare and unseen words in the test dataset by incorporating contextual semantics learned from the training dataset and lexical relations from ontology. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets. We also show through detailed analysis that incorporating background knowledge effectively alleviates issues of data scarcity.","tags":["\"Slot taggingContextual\"","\"representationBackground\"","\"knowledgeKnowledge\"","\"IntegrationMulti-level\"","\"graph attention\""],"title":"From context-aware to knowledge-aware Boosting OOV tokens recognition in slot tagging with background knowledge","type":"publication"},{"authors":["LuluZhao","Weihao Zeng","Weiran Xu","JunGuo"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"531badd442f99f521abe7590685d8731","permalink":"https://pris-nlp.github.io/publication/give-the-truth-incorporate-semantic-slot-into-abstractive-dialogue-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/give-the-truth-incorporate-semantic-slot-into-abstractive-dialogue-summarization/","section":"publication","summary":"Abstractive dialogue summarization suffers from a lots of factual errors, which are due to scattered salient elements in the multi-speaker information interaction process. In this work, we design a heterogeneous semantic slot graph with a slot-level mask cross-attention to enhance the slot features for more correct summarization. We also propose a slot-driven beam search algorithm in the decoding process to give priority to generating salient elements in a limited length by “filling-in-the-blanks”. Besides, an adversarial contrastive learning assisting the training process is introduced to improve the generalization of our model. Experimental performance on different types of factual errors shows the effectiveness of our methods and human evaluation further verifies the results.","tags":["\"Dialogue Summarization\""],"title":"Give the Truth Incorporate Semantic Slot into Abstractive Dialogue Summarization","type":"publication"},{"authors":["ZhiyuanZeng","JiazeChen","Weiran Xu","LeiLi"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"012f1047329d4dc68a563f4b8fb07aa2","permalink":"https://pris-nlp.github.io/publication/gradient-based-adversarial-factual-consistency-evaluation-for-abstractive-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/gradient-based-adversarial-factual-consistency-evaluation-for-abstractive-summarization/","section":"publication","summary":"Neural abstractive summarization systems have gained significant progress in recent years. However, excessive abstractiveness inevitably leads to factual errors, which poses a challenge to the robustness of the systems. In this paper, we proposed an efficient weak-supervised adversarial data augmentation approach to form the factual consistency dataset. Based on the artificial dataset, we train an evaluation model that can not only make accurate and robust factual consistency discrimination but is also capable of making interpretable factual errors tracing by backpropagated gradient distribution on token embeddings. Experiments and analysis conduct on public annotated summarization and factual consistency datasets demonstrate our approach effective and reasonable.","tags":["\"Factual Consistency Evaluation\""],"title":"Gradient-Based Adversarial Factual Consistency Evaluation for Abstractive Summarization","type":"publication"},{"authors":["YuejieLei","Yuanmeng Yan","ZhiyuanZeng","KeqingHe","XimingZhang","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"24c52aa27079cad3f87ff08feb16ffcf","permalink":"https://pris-nlp.github.io/publication/hierarchical-speaker-aware-sequence-to-sequence-model-for-dialogue-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/hierarchical-speaker-aware-sequence-to-sequence-model-for-dialogue-summarization/","section":"publication","summary":"","tags":["\"Dialogue Summarization\""],"title":"Hierarchical Speaker-aware Sequence-to-sequence Model for Dialogue Summarization","type":"publication"},{"authors":["LuluZhao","Weiran Xu","JunGuo"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"d1f0e2d750144bca0c36c4654540daef","permalink":"https://pris-nlp.github.io/publication/improving-abstractive-dialogue-summarization-with-graph-structures-and-topic-words/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/improving-abstractive-dialogue-summarization-with-graph-structures-and-topic-words/","section":"publication","summary":"Recently, people have been beginning paying more attention to the abstractive dialogue summarization task. Since the information flows are exchanged between at least two interlocutors and key elements about a certain event are often spanned across multiple utterances, it is necessary for researchers to explore the inherent relations and structures of dialogue contents. However, the existing approaches often process the dialogue with sequence-based models, which are hard to capture long-distance inter-sentence relations. In this paper, we propose a Topic-word Guided Dialogue Graph Attention (TGDGA) network to model the dialogue as an interaction graph according to the topic word information. A masked graph self-attention mechanism is used to integrate cross-sentence information flows and focus more on the related utterances, which makes it better to understand the dialogue. Moreover, the topic word features are introduced to assist the decoding process. We evaluate our model on the SAMSum Corpus and Automobile Master Corpus. The experimental results show that our method outperforms most of the baselines.","tags":["\"Dialogue Summarization\""],"title":"Improving Abstractive Dialogue Summarization with Graph Structures and Topic Words","type":"publication"},{"authors":["Yuanmeng Yan","RumeiLi","SiruiWang","HongzhiZhang","ZanDaoguang","FuzhengZhang","WeiWu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"19f4ec05789a769e39f069d1d9dc707c","permalink":"https://pris-nlp.github.io/publication/large-scale-relation-learning-for-question-answering-over-knowledge-bases-with-pre-trained-language-models/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/large-scale-relation-learning-for-question-answering-over-knowledge-bases-with-pre-trained-language-models/","section":"publication","summary":"The key challenge of question answering over knowledge bases (KBQA) is the inconsistency between the natural language questions and the reasoning paths in the knowledge base (KB). Recent graph-based KBQA methods are good at grasping the topological structure of the graph but often ignore the textual information carried by the nodes and edges. Meanwhile, pre-trained language models learn massive open-world knowledge from the large corpus, but it is in the natural language form and not structured. To bridge the gap between the natural language and the structured KB, we propose three relation learning tasks for BERT-based KBQA, including relation extraction, relation matching, and relation reasoning. By relation-augmented training, the model learns to align the natural language expressions to the relations in the KB as well as reason over the missing connections in the KB. Experiments on WebQSP show that our method consistently outperforms other baselines, especially when the KB is incomplete.","tags":["\"KBQA\""],"title":"Large-Scale Relation Learning for Question Answering over Knowledge Bases with Pre-trained Language Models","type":"publication"},{"authors":["KeqingHe","Yuanmeng Yan","HongXu","SihongLiu","ZijunLiu","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"bbc3080227b4a6c079b736aa826676b2","permalink":"https://pris-nlp.github.io/publication/learning-label-relational-output-structure-for-adaptive-sequence-labeling/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/learning-label-relational-output-structure-for-adaptive-sequence-labeling/","section":"publication","summary":"Sequence labeling is a fundamental task of natural language understanding. Recent neural models for sequence labeling task achieve significant success with the availability of sufficient training data. However, in practical scenarios, entity types to be annotated even in the same domain are continuously evolving. To transfer knowledge from the source model pre-trained on previously annotated data, we propose an approach which learns label-relational output structure to explicitly capturing label correlations in the latent space. Additionally, we construct the target-to-source interaction between the source model M S and the target model M T and apply a gate mechanism to control how much information in M S and M T should be passed down. Experiments show that our method consistently outperforms the state-of-the-art methods with a statistically significant margin and effectively facilitates to recognize rare new entities in the target data especially.","tags":["\"adaptive sequence labeling\"","\"transfer learning\"","\"label-relational output structure\"","\"latent space\""],"title":"Learning Label-Relational Output Structure for Adaptive Sequence Labeling","type":"publication"},{"authors":["KeqingHe","Yuanmeng Yan","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"086ca0957f4abebb8754d1f4bff90ab3","permalink":"https://pris-nlp.github.io/publication/learning-to-tag-oov-tokens-by-integrating-contextual-representation-and-background-knowledge/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/learning-to-tag-oov-tokens-by-integrating-contextual-representation-and-background-knowledge/","section":"publication","summary":"Neural-based context-aware models for slot tagging have achieved state-of-the-art performance. However, the presence of OOV(out-of-vocab) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-enhanced slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multi-level graph attention to explicitly model lexical relations. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets.","tags":["\"Slot Filling\""],"title":"Learning to Tag OOV Tokens by Integrating Contextual Representation and Background Knowledge","type":"publication"},{"authors":["ZhiyuanZeng","KeqingHe","Yuanmeng Yan","ZijunLiu","Yanan Wu","HongXu","HuixingJiang","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"f3ebe8e02e929c931daa39b8b5a87907","permalink":"https://pris-nlp.github.io/publication/modeling-discriminative-representations-for-out-of-domain/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/modeling-discriminative-representations-for-out-of-domain/","section":"publication","summary":"Detecting Out-of-Domain (OOD) or unknown intents from user queries is essential in a task oriented dialog system. A key challenge of OOD detection is to learn discriminative se mantic features. Traditional cross-entropy loss only focuses on whether a sample is correctly classified, and does not explicitly distinguish the margins between categories. In this pa per, we propose a supervised contrastive learn ing objective to minimize intra-class variance by pulling together in-domain intents belong ing to the same class and maximize inter-class variance by pushing apart samples from differ ent classes. Besides, we employ an adversar ial augmentation mechanism to obtain pseudo diverse views of a sample in the latent space. Experiments on two public datasets prove the effectiveness of our method capturing discrim inative representations for OOD detection.","tags":["\"OOD\"","\"intent detection\""],"title":"Modeling Discriminative Representations for Out-of-Domain Detection with Supervised Contrastive Learning","type":"publication"},{"authors":["Yanan Wu","ZhiyuanZeng","KeqingHe","HongXu","Yuanmeng Yan","HuixingJiang","Weiran Xu"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"b4a06f42b461c513bbb4e5bf80a038dd","permalink":"https://pris-nlp.github.io/publication/novel-slot-detection-a-benchmark-for-discovering-unknown-slot-types/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/novel-slot-detection-a-benchmark-for-discovering-unknown-slot-types/","section":"publication","summary":"Existing slot filling models can only recognize pre-defined in-domain slot types from a limited slot set. In the practical application, a reliable dialogue system should know what it does not know. In this paper, we introduce a new task, Novel Slot Detection (NSD), in the task-oriented dialogue system. NSD aims to discover unknown or out-of-domain slot types to strengthen the capability of a dialogue system based on in-domain training data. Besides, we construct two public NSD datasets propose several strong NSD baselines, and establish a benchmark for future work. Finally, we conduct exhaustive experiments and qualitative analysis to comprehend key challenges and provide new guidance for future directions","tags":["\"OOD\"","\"intent detection\""],"title":"Novel Slot Detection A Benchmark for Discovering Unknown Slot Types in the Task-Oriented Dialogue System","type":"publication"},{"authors":["SihongLiu","JinchaoZhang","KeqingHe,","Weiran Xu","JieZhou"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"25a89a2bccac6ffea3953c05b415c1d6","permalink":"https://pris-nlp.github.io/publication/scheduled-dialog-policy-learning-an-automatic-curriculum-learning-framework-for-task-oriented-dialog-system/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/scheduled-dialog-policy-learning-an-automatic-curriculum-learning-framework-for-task-oriented-dialog-system/","section":"publication","summary":"","tags":["\"dialog management\""],"title":"Scheduled Dialog Policy Learning An Automatic Curriculum Learning Framework for Task-oriented Dialog System","type":"publication"},{"authors":["LuluZhao","Weiran Xu","ShengGao","JunGuo"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"c0c28cf3e1a16d838b506f7e58e34c35","permalink":"https://pris-nlp.github.io/publication/utilizing-graph-neural-networks-to-improving-dialogue-based-relation-extraction/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/utilizing-graph-neural-networks-to-improving-dialogue-based-relation-extraction/","section":"publication","summary":"Relation extraction has been an active research interest in the field of Natural Language Processing (NLP). The past works primarily focused on a corpus of formal text which is inherently non-dialogic. Recently, the dialogue-based relation extraction task, which detects relations among speaker-aware entities scattering in dialogues, has been gradually arousing people’s attention. Some sequence-based neural methods have been carried out to obtain the relevant information. However, identifying cross-sentence relations remains unsolved, especially in the context of a specific-domain dialogue system. In this paper, we propose a Relational Attention Enhanced Graph Convolutional Network (RAEGCN), which constructs the whole dialogue as a semantic interactive graph by emphasizing the speaker-related information and leveraging various inter-sentence dependencies. A dense connectivity mechanism is also introduced to empower the multi-hop relational reasoning across sentences, which can capture both local and non-local features simultaneously. Experiments show the significant superiority and robustness of our model on a real-world dataset DialogRE, as compared with previous approaches.","tags":["\"Dialogue Relation Extraction \""],"title":"Utilizing Graph Neural Networks to Improving Dialogue-based Relation Extraction","type":"publication"},{"authors":["YuanyuanQi","JiayueZhang","YansongLiu","Weiran Xu","JunGuo"],"categories":[],"content":"","date":1600473600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600523752,"objectID":"3a052120ec6fb7d2864d896b363f3f70","permalink":"https://pris-nlp.github.io/publication/cgtr-convolution-graph-topology-representation-for-document-ranking/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/cgtr-convolution-graph-topology-representation-for-document-ranking/","section":"publication","summary":"Contextualized neural language models have gained much attention in Information Retrieval (IR) with its ability to achieve better text understanding by capturing contextual structure. However, to achieve better document understanding, it is necessary to involve global structure of a document. In this paper, we take the advantage of Graph Convolutional Networks (GCN) to model global word-relation structure of a document to improve context-aware document ranking. We propose to build a graph for a document to model the global structure. The nodes and edges of the graph are constructed from contextual embeddings. Then we apply graph convolution on the graph to learning a new representation, and this representation covers both contextual and global structure information. The experimental results show that our method outperforms the state-of-the-art contextual language models, which demonstrate that incorporating global structure is useful for improving document ranking and GCN is an effective way to achieve it.","tags":["\"Text Understanding\"","\"Contextualized Neural Language Models\"","\"Graph\"","\"Convolution Networks\""],"title":"CGTR:Convolution Graph Topology Representation for Document Ranking","type":"publication"},{"authors":["PengdaQin","XinWang","WenhuChen","ChunyunZhang","Weiran Xu","WilliamYangWang"],"categories":[],"content":"","date":1585872000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600522724,"objectID":"d46e35e66847a328424370fdd170fc76","permalink":"https://pris-nlp.github.io/publication/generative-adversarial-zero-shot-relation-learning-for-knowledge-grapths/","publishdate":"2020-09-19T13:38:44.301342Z","relpermalink":"/publication/generative-adversarial-zero-shot-relation-learning-for-knowledge-grapths/","section":"publication","summary":"Large-scale knowledge graphs (KGs) are shown to become more important in current information systems. To expand the coverage of KGs, previous studies on knowledge graph completion need to collect adequate training instances for newly-added relations. In this paper, we consider a novel formulation, zero-shot learning, to free this cumbersome curation. For newly-added relations, we attempt to learn their semantic features from their text descriptions and hence recognize the facts of unseen relations with no examples being seen. For this purpose, we leverage Generative Adversarial Networks (GANs) to establish the connection between text and knowledge graph domain:The generator learns to generate the reasonable relation embeddings merely with noisy text descriptions. Under this setting, zero-shot learning is naturally converted to a traditional supervised classification task. Empirically, our method is model-agnostic that could be potentially applied to any version of KG embeddings, and consistently yields performance improvements on NELL and Wiki dataset.","tags":["\"Knowledge Graph Completion\""],"title":"Generative Adversarial Zero-Shot Relation Learning for Knowledge Grapths","type":"publication"},{"authors":["HuaXu"],"categories":null,"content":"Course Classification: Public Elective Courses of Tsinghua University\nLecturer: Hua Xu\nTarget Audience: All Undergraduate Students\nTeaching Time：2019 - Today\n","date":1546272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546272000,"objectID":"407bfb7ec4580d302372641bb7e5039e","permalink":"https://pris-nlp.github.io/talk/internet-product-design/","publishdate":"2019-01-01T00:00:00+08:00","relpermalink":"/talk/internet-product-design/","section":"talk","summary":"Public Elective Courses of Tsinghua University","tags":[],"title":"Internet Product Design","type":"talk"},{"authors":["HuaXu"],"categories":null,"content":"Course Classification: Public Elective Courses of Tsinghua University\nLecturer: Hua Xu\nTarget Audience: All Undergraduate Students\nTeaching Time：2016 - Today\n","date":1451577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451577600,"objectID":"050eb509d73d451227a478cbd25c314e","permalink":"https://pris-nlp.github.io/talk/intelligent-mobile-robot/","publishdate":"2016-01-01T00:00:00+08:00","relpermalink":"/talk/intelligent-mobile-robot/","section":"talk","summary":"Public Elective Courses of Tsinghua University","tags":[],"title":"Intelligent Mobile Robot: Design, Programming and Practice","type":"talk"},{"authors":["HuaXu"],"categories":null,"content":"Course Classification: Public Elective Courses of Tsinghua University\nLecturer: Hua Xu\nTarget Audience: All Graduate and Undergraduate Students\nTeaching Time：2013 - Today\n","date":1356969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356969600,"objectID":"e7d4ecfaf4b1f29cd65dd9ec01f1f6ad","permalink":"https://pris-nlp.github.io/talk/industrial-data-mining/","publishdate":"2013-01-01T00:00:00+08:00","relpermalink":"/talk/industrial-data-mining/","section":"talk","summary":"Public Elective Courses of Tsinghua University","tags":[],"title":"Industrial Data Mining","type":"talk"},{"authors":["HuaXu"],"categories":null,"content":"Course Classification: Public Elective Courses of Tsinghua University\nLecturer: Hua Xu\nTarget Audience: All Undergraduate Students\nTeaching Time：2011 - Today\n","date":1293811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293811200,"objectID":"3e7631952ecff1e05471581a1af8e97d","permalink":"https://pris-nlp.github.io/talk/data-mining-method-and-application/","publishdate":"2011-01-01T00:00:00+08:00","relpermalink":"/talk/data-mining-method-and-application/","section":"talk","summary":"Public Elective Courses of Tsinghua University","tags":[],"title":"Data Mining: Methods and Applications","type":"talk"},{"authors":["JunhuiDeng"],"categories":null,"content":"Course Classification: Tsinghua University Computer Department Undergraduate Professional Basic Course\nLecturer：Junhui Deng\nTarget Audience: Computer Science Undergraduate\nTeaching Time：2001 - 2006\n","date":978278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":978278400,"objectID":"b7caabb0e4bde45ecc0519114b6a051c","permalink":"https://pris-nlp.github.io/talk/data-structure-cs/","publishdate":"2001-01-01T00:00:00+08:00","relpermalink":"/talk/data-structure-cs/","section":"talk","summary":"Tsinghua University Computer Department Undergraduate Professional Basic Course","tags":[],"title":"Data Strcture","type":"talk"},{"authors":["JunhuiDeng"],"categories":null,"content":"Course Classification: Public Elective Courses of Tsinghua University\nLecturer：Junhui Deng\nTarget Audience: All Undergraduate Students\nTeaching Time：2002 - Today\n","date":978278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":978278400,"objectID":"970c56d891d3e1abdca0aaf1b5140c8d","permalink":"https://pris-nlp.github.io/talk/data-structure/","publishdate":"2001-01-01T00:00:00+08:00","relpermalink":"/talk/data-structure/","section":"talk","summary":"National Excellent Course, Public Elective Course of Tsinghua University","tags":[],"title":"Data Strcture","type":"talk"},{"authors":["JunhuiDeng","HuaXu"],"categories":null,"content":"Course Classification: Tsinghua University Computer Department Graduate Basic Theory Course\nLecturer：Junhui Deng, Hua Xu\nTarget Audience: All Graduate Students\nTeaching Time：1997 - Today\n","date":852048000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":852048000,"objectID":"f93308c8be1670e9b2dc795f64282a4a","permalink":"https://pris-nlp.github.io/talk/computational-geometry/","publishdate":"1997-01-01T00:00:00+08:00","relpermalink":"/talk/computational-geometry/","section":"talk","summary":"Tsinghua University Computer Department Graduate Basic Theory Course","tags":[],"title":"Computational Geometry","type":"talk"}]