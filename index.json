[{"authors":["WeiranXu"],"categories":null,"content":"基于机器学习和模式识别的理论和方法解决文本处理问题，如文本分类、信息检索、信息抽取和倾向判断等。1997年起开始从事模式识别与机器学习领域研究，2003年起专门从事文本数据的机器学习研究；主持参加2004年以来的TREC、TAC、863和COAE等相关评测，多次取得单项和综合成绩第一名；负责构建一系列原型系统；以主要成员参与多项国家自然科学基金、863项目和国家科技重大专项等；发表论文包括ACL、AAAI、SIGIR等顶会论文近10篇，SCI索引期刊论文10多篇，EI索引论文50多篇。\n网络中包含各种有用信息，瓶颈是怎样自动获取它们。长期的研究方向是让计算机能够自动理解文本的内容，并主动为人们提供各种服务。与人的能力相比，机器的能力还有很大的提升空间。但在目前的情况下让机器全面超越人，这还是非常困难的。\n当前主要的研究问题是: 以实体或者事件为中心来组织和整理文本中的内容，以解决信息抽取、信息检索、文本分类和倾向判断等问题。主要采用的理论和方法就是表示学习理论和复杂网络理论。表示学习(Representation Learning，或者Feature Learning，或者Learning Representations)”中的深度学习(Deep Learning)在图像和语音处理中获得卓越的效果。表示学习理论尚处于研究的初级阶段，常用方法主要有“概率模型”、“自动编码”和“流形学习”等。本实验室的郭军教授基于复杂网络提出的激活力模型对于挖掘和表示各个因素以及之间的关联关系有良好效果，因此将其应用于表示学习理论框架下将会更好地解决文本内容抽取和表示的问题。\n","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1614556800,"objectID":"f7f1828bc4d3f77885779338384d5198","permalink":"https://pris-nlp.github.io/author/%E5%BE%90%E8%94%9A%E7%84%B6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BE%90%E8%94%9A%E7%84%B6/","section":"authors","summary":"基于机器学习和模式识别的理论和方法解决文本处理问题，如文本分类、信息检索、信息抽取和倾向判断等。1997年起开始从事模式识别与机器学习领域研究，2003年起专门从事文本数据的机器学习研究；主持参加2004年以来的TREC、TAC、863和COAE等相关评测，多次取得单项和综合成绩第一名；负责构建一系列原型系统；以主要成员参与多项国家自然科学基金、863项目和国家科技重大专项等；发表论文包括ACL、AAAI、SIGIR等顶会论文近10篇，SCI索引期刊论文10多篇，EI索引论文50多篇。\n网络中包含各种有用信息，瓶颈是怎样自动获取它们。长期的研究方向是让计算机能够自动理解文本的内容，并主动为人们提供各种服务。与人的能力相比，机器的能力还有很大的提升空间。但在目前的情况下让机器全面超越人，这还是非常困难的。\n当前主要的研究问题是: 以实体或者事件为中心来组织和整理文本中的内容，以解决信息抽取、信息检索、文本分类和倾向判断等问题。主要采用的理论和方法就是表示学习理论和复杂网络理论。表示学习(Representation Learning，或者Feature Learning，或者Learning Representations)”中的深度学习(Deep Learning)在图像和语音处理中获得卓越的效果。表示学习理论尚处于研究的初级阶段，常用方法主要有“概率模型”、“自动编码”和“流形学习”等。本实验室的郭军教授基于复杂网络提出的激活力模型对于挖掘和表示各个因素以及之间的关联关系有良好效果，因此将其应用于表示学习理论框架下将会更好地解决文本内容抽取和表示的问题。","tags":null,"title":"徐蔚然","type":"authors"},{"authors":["YuanmengYan"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1614556800,"objectID":"fada719e3feff979780c87df53610f4a","permalink":"https://pris-nlp.github.io/author/%E4%B8%A5%E6%B8%8A%E8%92%99/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%B8%A5%E6%B8%8A%E8%92%99/","section":"authors","summary":"","tags":null,"title":"严渊蒙","type":"authors"},{"authors":["QianyuCao"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"e9b3152c58f76bd04c003e496373a415","permalink":"https://pris-nlp.github.io/author/%E6%9B%B9%E4%B9%BE%E7%85%9C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9B%B9%E4%B9%BE%E7%85%9C/","section":"authors","summary":"","tags":null,"title":"曹乾煜","type":"authors"},{"authors":["XuefengLi"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1600523752,"objectID":"9d7c1c0c900bc56efb9e418a468b6172","permalink":"https://pris-nlp.github.io/author/%E6%9D%8E%E9%9B%AA%E5%B3%B0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E9%9B%AA%E5%B3%B0/","section":"authors","summary":"","tags":null,"title":"李雪峰","type":"authors"},{"authors":["LiwenWang"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1614556800,"objectID":"adada2facae11e3f486b44e919b8db2a","permalink":"https://pris-nlp.github.io/author/%E7%8E%8B%E7%A4%BC%E6%96%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%8E%8B%E7%A4%BC%E6%96%87/","section":"authors","summary":"","tags":null,"title":"王礼文","type":"authors"},{"authors":["FujiaZheng"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1600523752,"objectID":"953924eb0a5f7b1fc0a5c25f4c4f989c","permalink":"https://pris-nlp.github.io/author/%E9%83%91%E9%A6%A5%E5%98%89/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%83%91%E9%A6%A5%E5%98%89/","section":"authors","summary":"","tags":null,"title":"郑馥嘉","type":"authors"},{"authors":["YananWu"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1614556800,"objectID":"cc8ce7c377a7104416cd440a54027525","permalink":"https://pris-nlp.github.io/author/%E5%90%B4%E4%BA%9A%E6%A5%A0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B4%E4%BA%9A%E6%A5%A0/","section":"authors","summary":"","tags":null,"title":"吴亚楠","type":"authors"},{"authors":["ChenZeng"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"f967eaa9aadcd6a0176d7f81f87f031e","permalink":"https://pris-nlp.github.io/author/%E6%9B%BE%E6%99%A8/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9B%BE%E6%99%A8/","section":"authors","summary":"","tags":null,"title":"曾晨","type":"authors"},{"authors":["YutaoMu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"3f2a530a96fc0a7015690a0de3bf8fef","permalink":"https://pris-nlp.github.io/author/%E7%89%9F%E5%AE%87%E6%BB%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%89%9F%E5%AE%87%E6%BB%94/","section":"authors","summary":"","tags":null,"title":"牟宇滔","type":"authors"},{"authors":["RuotongGeng"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"a7dbd44e4cdf66c3e4433fa1e6f3afe0","permalink":"https://pris-nlp.github.io/author/%E8%80%BF%E8%8B%A5%E5%BD%A4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%80%BF%E8%8B%A5%E5%BD%A4/","section":"authors","summary":"","tags":null,"title":"耿若彤","type":"authors"},{"authors":["GuantingDong"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"eb44dbee8694f917cc30af1ed6e380a6","permalink":"https://pris-nlp.github.io/author/%E8%91%A3%E5%86%A0%E9%9C%86/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%91%A3%E5%86%A0%E9%9C%86/","section":"authors","summary":"","tags":null,"title":"董冠霆","type":"authors"},{"authors":["DaichiGuo"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"da5ab810d8039861073d5dc563cefc8f","permalink":"https://pris-nlp.github.io/author/%E9%83%AD%E5%B2%B1%E9%A9%B0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%83%AD%E5%B2%B1%E9%A9%B0/","section":"authors","summary":"","tags":null,"title":"郭岱驰","type":"authors"},{"authors":["HaoLei"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"ca6b7927c276a8d431611c5bb76f3334","permalink":"https://pris-nlp.github.io/author/%E9%9B%B7%E6%B5%A9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%9B%B7%E6%B5%A9/","section":"authors","summary":"","tags":null,"title":"雷浩","type":"authors"},{"authors":["QixiangGao"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"15a8a8196173924896cf2b574ccdffd8","permalink":"https://pris-nlp.github.io/author/%E9%AB%98%E7%90%AA%E7%BF%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%AB%98%E7%90%AA%E7%BF%94/","section":"authors","summary":"","tags":null,"title":"高琪翔","type":"authors"},{"authors":["WeihaoZeng"],"categories":null,"content":"","date":1600523751,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1600523752,"objectID":"2b545b98f6c5cfccc2d06f5586ef14bd","permalink":"https://pris-nlp.github.io/author/%E6%9B%BE%E4%BC%9F%E8%B1%AA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9B%BE%E4%BC%9F%E8%B1%AA/","section":"authors","summary":"","tags":null,"title":"曾伟豪","type":"authors"},{"authors":["Pei Wang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"19c0da4b715ec83728e4cb6f1234cd8d","permalink":"https://pris-nlp.github.io/author/%E7%8E%8B%E9%9C%88/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%8E%8B%E9%9C%88/","section":"authors","summary":"","tags":null,"title":"王霈","type":"authors"},{"authors":["HuaXu"],"categories":[],"content":"","date":1409557409,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1409557409,"objectID":"aa585aa49362c42e9f2830d01bcf8f37","permalink":"https://pris-nlp.github.io/textbook/datamining-methodandapplication/","publishdate":"2014-09-01T15:43:29+08:00","relpermalink":"/textbook/datamining-methodandapplication/","section":"textbook","summary":"主要根据清华大学开设的“数据挖掘：方法与应用”课程的教学实践与积累，参考近年国外著名大学相关课程的教学体系，系统的介绍数据挖掘的基本概念和基本原理方法；结合一些典型的应用实例展示用数据挖掘的思维方法求解问题的一般性模式与思路。","tags":["数据挖掘"],"title":"数据挖掘：方法与应用","type":"textbook"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"dff53f196c9fa8e89f6523d449108d7a","permalink":"https://pris-nlp.github.io/patent/%E5%9F%BA%E4%BA%8E%E7%96%91%E9%97%AE%E8%AF%8D%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95%E5%8F%8A%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%9F%BA%E4%BA%8E%E7%96%91%E9%97%AE%E8%AF%8D%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95%E5%8F%8A%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"基于疑问词分类器的神经网络问题生成方法及生成系统","type":"patent"},{"authors":["HuaXu"],"categories":[],"content":"","date":1201851809,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1201851809,"objectID":"2bfeedb392926ea9bc043feb5ad0e8ed","permalink":"https://pris-nlp.github.io/monograph/petrinettheoryandapplications/","publishdate":"2008-02-01T15:43:29+08:00","relpermalink":"/monograph/petrinettheoryandapplications/","section":"monograph","summary":"Chapter 12: Timed Hierarchical Object-oriented Petri Net, I-Tech Education and Publishing, Vienna, Austria, 2008, pp.253-280, ISNN:978-3-902613-12-7 (徐华 参与编写，2008年2月出版)","tags":[],"title":"Petri Net: Theory and Applications","type":"monograph"},{"authors":["HuaXu"],"categories":[],"content":"","date":1504251809,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1504251809,"objectID":"cb3a9f5f79958edae4960ecccacd7726","permalink":"https://pris-nlp.github.io/textbook/datamining-methodandapplication-case/","publishdate":"2017-09-01T15:43:29+08:00","relpermalink":"/textbook/datamining-methodandapplication-case/","section":"textbook","summary":"主要根据清华大学开设的“数据挖掘：方法与应用”课程的教学实践与积累，参考近年国外著名大学相关课程的教学体系，系统的介绍数据挖掘的基本概念和基本原理方法；结合一些典型的应用实例展示用数据挖掘的思维方法求解问题的一般性模式与思路。","tags":["数据挖掘"],"title":"数据挖掘：方法与应用——应用案例","type":"textbook"},{"authors":["徐蔚然","吴亚楠","严渊蒙"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"290198b503d62d1657204867f47da26e","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%BB%93%E6%9E%84%E5%8C%96%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%E6%8F%8F%E8%BF%B0%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%BB%93%E6%9E%84%E5%8C%96%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%E6%8F%8F%E8%BF%B0%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"一种基于结构化用户属性描述的个性化任务型对话系统","type":"patent"},{"authors":["HuaXu"],"categories":[],"content":"","date":1470037409,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1470037409,"objectID":"f3c91f32b83aaa1a5de73ea397ed32b4","permalink":"https://pris-nlp.github.io/textbook/bigdatatechnologyandindustryapplications/","publishdate":"2016-08-01T15:43:29+08:00","relpermalink":"/textbook/bigdatatechnologyandindustryapplications/","section":"textbook","summary":"如何定义大数据？如何应用大数据？什么是大数据思维？如何学习大数据？如何构建大数据平台？如何在行业中应用大数据？这一系列的问题，是当前在大数据热的时代背景里，让人感到非常迷茫的问题。《大数据技术及行业应用》直面这些问题，在从业者角度解答以上问题，希望能给大数据行业的初学者提供一些帮助。","tags":["大数据"],"title":"大数据技术及行业应用","type":"textbook"},{"authors":["HuaXu"],"categories":[],"content":"","date":1454312609,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1454312609,"objectID":"4949ddee0a08346cb8809beaaa742b23","permalink":"https://pris-nlp.github.io/monograph/sentimentanalysisandontologyengineering/","publishdate":"2016-02-01T15:43:29+08:00","relpermalink":"/monograph/sentimentanalysisandontologyengineering/","section":"monograph","summary":"Chapter 10: Chinese Micro-Blog Emotion Classification by Exploiting Linguistic Features and SVMperf ), Springer International Publishing, 2016, pp. 221-236, ISNN:978-3-319-30317-8 (徐华 参与编写，2016年出版)","tags":[],"title":"Sentiment Analysis and Ontology Engineering","type":"monograph"},{"authors":["徐蔚然","严渊蒙","吴亚楠"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"5001708f0a28902a5ce679b5ab56b8ec","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%A5%E8%AF%86%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%98%93%E9%85%8D%E7%BD%AE%E4%BB%BB%E5%8A%A1%E5%AF%BC%E5%90%91%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%A5%E8%AF%86%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%98%93%E9%85%8D%E7%BD%AE%E4%BB%BB%E5%8A%A1%E5%AF%BC%E5%90%91%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"一种知识驱动的易配置任务导向型对话管理方法与系统","type":"patent"},{"authors":["HuaXu"],"categories":[],"content":"","date":1201851809,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1201851809,"objectID":"2c5c9a0907335dbc37fce7e6ceebe45b","permalink":"https://pris-nlp.github.io/monograph/recentadvancesinmulti-robotsystems/","publishdate":"2008-02-01T15:43:29+08:00","relpermalink":"/monograph/recentadvancesinmulti-robotsystems/","section":"monograph","summary":"Chapter 13: A Novel Modeling Method for Cooperative Multi-robot Systems Using Fuzzy Timed Agent Based Petri Nets ), I-Tech Education and Publishing, Vienna, Austria, 2008, pp.249-262, ISNN:978-3-902613-24-0 (徐华 参与编写，2008年出版)","tags":[],"title":"Recent Advances in Multi-robot Systems","type":"monograph"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"533212db21ceb7d036aa5b3495271654","permalink":"https://pris-nlp.github.io/patent/%E5%BB%BA%E6%A8%A1%E5%AF%B9%E8%AF%9D%E8%BD%AE%E6%AC%A1%E4%BF%A1%E6%81%AF%E7%9A%84%E6%A3%80%E7%B4%A2%E5%BC%8F%E9%97%B2%E8%81%8A%E5%AF%B9%E8%AF%9D%E6%89%93%E5%88%86%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%BB%BA%E6%A8%A1%E5%AF%B9%E8%AF%9D%E8%BD%AE%E6%AC%A1%E4%BF%A1%E6%81%AF%E7%9A%84%E6%A3%80%E7%B4%A2%E5%BC%8F%E9%97%B2%E8%81%8A%E5%AF%B9%E8%AF%9D%E6%89%93%E5%88%86%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"建模对话轮次信息的检索式闲聊对话打分方法","type":"patent"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1107243809,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1107243809,"objectID":"30837e0151d041aff588987056d3a925","permalink":"https://pris-nlp.github.io/textbook/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8/","publishdate":"2005-02-01T15:43:29+08:00","relpermalink":"/textbook/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8/","section":"textbook","summary":"《计算几何:算法与应用(第3版)》的前4章对几何算法进行了讨论，包括几何求交、三角剖分、线性规划等，其中涉及的随机算法也是《计算几何:算法与应用(第3版)》的一个鲜明特点。第5章至第10章介绍了多种几何结构，包括几何查找、kd树、区域树、梯形图、Voronoi图、排列、Delaunay三角剖分、区间树、优先查找树以及线段树等。第11章至第16章结合实际问题，继续讨论了若干几何算法及其数据结构，包括高维凸包、空间二分及BSP树、运动规划、网格生成及四叉树、最短路径查找及可见性图、单纯性区域查找及划分树和切分树等，这些也是对前10章内容的进一步深化。《计算几何:算法与应用(第3版)》不仅内容全面，而且紧扣实际应用，重点突出，既有深入的讲解，同时每章都设有“注释及评论”和“习题”，方便读者更深入的理解，被世界众多大学作为教材。","tags":[],"title":"计算几何：算法与应用","type":"textbook"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"8ca7a04f158ea4a16f469a89f85c0315","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B7%E5%8F%A0%E4%BF%A1%E5%8F%B7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%B7%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%88%A4%E5%88%AB%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B7%E5%8F%A0%E4%BF%A1%E5%8F%B7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%B7%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%88%A4%E5%88%AB%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"一种基于混叠信号深度学习的跳频信号判别方法","type":"patent"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1138779809,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1138779809,"objectID":"c70ac8a450da7476c774fb168d54bc54","permalink":"https://pris-nlp.github.io/textbook/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95java%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0/","publishdate":"2006-02-01T15:43:29+08:00","relpermalink":"/textbook/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95java%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0/","section":"textbook","summary":"本书充分展示了面向对象技术在现代数据结构理论中的应用，普遍采用了抽象、封装及继承等技术。本书既介绍了基本的数据结构，并结合具体问题介绍了算法的应用、实现及其分析方法，本书还通过遍历算法框架将各种图算法统一起来，并基于遍历算法模板加以实现，在同类教材中独树一帜。","tags":[],"title":"数据结构与算法（Java描述）","type":"textbook"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1075621409,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1075621409,"objectID":"7dedbd79296664918c876247a7356cba","permalink":"https://pris-nlp.github.io/monograph/%E8%B4%A8%E9%87%8F%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86/","publishdate":"2004-02-01T15:43:29+08:00","relpermalink":"/monograph/%E8%B4%A8%E9%87%8F%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86/","section":"monograph","summary":"清华大学出版社（2004年6月）ISBN: 7-302-08298-7 （原著：Gerald M. Weinberg, Quality Software Management:Systems Thinking ,Dorset House (Sep. 1991), ISBN: 0-932-63322-6.）","tags":[],"title":"质量软件管理（第1卷）--系统思维","type":"monograph"},{"authors":["JunhuiDeng"],"categories":[],"content":"","date":1044085409,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1044085409,"objectID":"edca37e22f48ff86ab5a6e634b5b3a8a","permalink":"https://pris-nlp.github.io/monograph/%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%BF%83%E7%90%86%E5%AD%A6%E9%93%B6%E5%B9%B4%E7%BA%AA%E5%BF%B5%E7%89%88/","publishdate":"2003-02-01T15:43:29+08:00","relpermalink":"/monograph/%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%BF%83%E7%90%86%E5%AD%A6%E9%93%B6%E5%B9%B4%E7%BA%AA%E5%BF%B5%E7%89%88/","section":"monograph","summary":"清华大学出版社（2003年 9月）ISBN: 7-302-07026-1 （原著：Gerald M. Weinberg, The Psychology of Computer Programming: Silver Anniversary Edition, Dorset House (Sep. 1998), ISBN: 0-932-63342-0.）","tags":[],"title":"程序开发心理学（银年纪念版）","type":"monograph"},{"authors":["HuaXu"],"categories":[],"content":"","date":1602301409,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1602301409,"objectID":"d9809ef0bb72c0fdeb8f093635124ba3","permalink":"https://pris-nlp.github.io/textbook/%E6%96%87%E6%9C%AC%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/","publishdate":"2020-10-10T11:43:29+08:00","relpermalink":"/textbook/%E6%96%87%E6%9C%AC%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/","section":"textbook","summary":"本书从多个维度对文本大数据情感分析技术进行了阐述，内容涵盖有关自然语言处理和文本情感、情绪方法，以及面向微博文本的情绪及其诱因分析、面向话题评论的立场分析、文本表示方法及其在情绪分类中的应用。本书以模块化的方式进行组织，理论性强，条理清晰。作者团队以认真严谨的科学态度实现了书中的主要方法，描述了各种方法取得的效果。本书可为高校相关专业（如计算机科学与技术、软件工程等）学生的学习和科研工作提供帮助，同时对从事文本挖掘、自然语言处理的工程技术人员也具有较高的参考价值。","tags":[],"title":"文本大数据情感分析","type":"textbook"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"9b07acc9b039169e280ab7a2cbc3d5f1","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"一种基于嵌入式表示的自适应中文分词方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"c9382e1521faef0f1c470943165b62e9","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%A4%9A%E7%B2%92%E5%BA%A6%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%A4%9A%E7%B2%92%E5%BA%A6%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"一种基于隐多粒度局部特征的中文分词方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"8335423f963cfa0e1f8095291c070504","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E7%9A%84%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%92%8C%E8%AE%BE%E5%A4%87/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E7%9A%84%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%92%8C%E8%AE%BE%E5%A4%87/","section":"patent","summary":"","tags":[],"title":"一种短信的识别方法和设备","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"d64632bbdea2aae7e69200d4fc20b3ab","permalink":"https://pris-nlp.github.io/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4%E7%9A%84%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E4%B8%80%E7%A7%8D%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4%E7%9A%84%E6%96%B9%E6%B3%95%E5%92%8C%E8%A3%85%E7%BD%AE/","section":"patent","summary":"","tags":[],"title":"一种短信过滤的方法和装置","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"5e905ec1fdafe8f5121c2211943507e9","permalink":"https://pris-nlp.github.io/patent/%E9%98%B2%E5%81%87%E6%AD%BB%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E9%98%B2%E5%81%87%E6%AD%BB%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"防假死爬虫系统的构建方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"ed911f5b24e54d4ff36a511e61e1eee4","permalink":"https://pris-nlp.github.io/patent/%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"分布式爬虫集群系统","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"a0bce571fdebdebd57bd7324fcd6a4d2","permalink":"https://pris-nlp.github.io/patent/%E5%B8%83%E5%91%8A%E6%A0%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%B8%83%E5%91%8A%E6%A0%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"布告栏搜索引擎的爬虫系统构建方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"5b0c68e2014051e68cfd76ee3adcbfe0","permalink":"https://pris-nlp.github.io/patent/%E5%B9%B6%E8%A1%8C%E5%BC%8F%E5%85%B3%E8%81%94%E5%B8%83%E5%91%8A%E6%A0%8F%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%B9%B6%E8%A1%8C%E5%BC%8F%E5%85%B3%E8%81%94%E5%B8%83%E5%91%8A%E6%A0%8F%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"并行式关联布告栏爬虫系统","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"33a28ddc2ab4c3abd236925d2a51602e","permalink":"https://pris-nlp.github.io/patent/%E8%87%AA%E5%8A%A8%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E8%87%AA%E5%8A%A8%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"自动动态更新论坛爬虫系统的构建方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"beb355b6e727e985c23a61c317c7df5a","permalink":"https://pris-nlp.github.io/patent/%E5%90%8C%E8%AF%9D%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%B7%9F%E8%B8%AA%E5%BC%8F%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%90%8C%E8%AF%9D%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%B7%9F%E8%B8%AA%E5%BC%8F%E8%AE%BA%E5%9D%9B%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"同话题定位跟踪式论坛爬虫系统","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"d95c2984046fab93affb647ddd435e14","permalink":"https://pris-nlp.github.io/patent/%E5%86%85%E9%83%A8%E7%BD%91%E5%8F%AF%E5%AE%9A%E5%88%B6%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%86%85%E9%83%A8%E7%BD%91%E5%8F%AF%E5%AE%9A%E5%88%B6%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"内部网可定制爬虫系统构建方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"3d670f3ae8eb0472cae9fc7ab9698c31","permalink":"https://pris-nlp.github.io/patent/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%86%85%E9%83%A8%E7%BD%91%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%86%85%E9%83%A8%E7%BD%91%E7%88%AC%E8%99%AB%E7%B3%BB%E7%BB%9F/","section":"patent","summary":"","tags":[],"title":"多线程断点续传可定制内部网爬虫系统","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"727b3252c03b39978223f9b4f00c0a0f","permalink":"https://pris-nlp.github.io/patent/%E5%9F%BA%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E6%96%87%E5%AD%97%E5%AD%97%E4%BD%93%E5%88%A4%E6%96%AD%E8%AE%BE%E5%A4%87%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E5%9F%BA%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E6%96%87%E5%AD%97%E5%AD%97%E4%BD%93%E5%88%A4%E6%96%AD%E8%AE%BE%E5%A4%87%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"基于贝叶斯分类器的文字字体判断设备及其方法","type":"patent"},{"authors":["徐蔚然"],"categories":[],"content":"","date":1225266209,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1225266209,"objectID":"dcb5184244faf499a588648530a2c9c3","permalink":"https://pris-nlp.github.io/patent/%E7%94%A8%E4%BA%8E%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E8%87%AA%E5%8A%A8%E6%8C%91%E9%80%89%E8%A3%85%E7%BD%AE%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","publishdate":"2008-10-29T15:43:29+08:00","relpermalink":"/patent/%E7%94%A8%E4%BA%8E%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E8%87%AA%E5%8A%A8%E6%8C%91%E9%80%89%E8%A3%85%E7%BD%AE%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/","section":"patent","summary":"","tags":[],"title":"用于文字识别的训练样本自动挑选装置及其方法","type":"patent"},{"authors":["YuejieLei","郑馥嘉","严渊蒙","KeqingHe","徐蔚然"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"5a9fadb5279182c5f605d4bb596c178e","permalink":"https://pris-nlp.github.io/publication/a-finer-grain-universal-dialogue-semantic-structures-based-model-for-abstractive-dialogue-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/a-finer-grain-universal-dialogue-semantic-structures-based-model-for-abstractive-dialogue-summarization/","section":"publication","summary":"Although models in abstractive summarization have achieved impressive results on document summarization tasks, their performance on dialogue modeling is much less satisfactory due to the crude and straight methods for dialogue encoding. To address this question, we propose a novel end-to-end Transformer-based model FinDS for abstractive dialogue summarization that leverages Finer-grain universal Dialogue semantic Structures to model dialogue and generates better summaries. Experiments on the SAMsum dataset show that FinDS outperforms various dialogue summarization approaches and achieves new state-of-the-art (SOTA) ROUGE-F results. Finally, we apply FinDS to a more complex scenario, showing the robustness of our model. We will release our source code after blind review.","tags":["\"Dialogue Summarization\""],"title":"A Finer-grain Universal Dialogue Semantic Structures based Model For Abstractive Dialogue Summarization","type":"publication"},{"authors":["王礼文","李雪峰","JiachiLiu","KeqingHe","严渊蒙","徐蔚然"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"385842321aef2a5899368efefd05b945","permalink":"https://pris-nlp.github.io/publication/bridge-to-target-domain-by-prototypical-contrastive-learning-and-label-confusion-re-explore-zero-shot-learning-for-slot-filling/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/bridge-to-target-domain-by-prototypical-contrastive-learning-and-label-confusion-re-explore-zero-shot-learning-for-slot-filling/","section":"publication","summary":"Zero-shot cross-domain slot filling alleviates the data dependence in the case of data scarcity in the target domain, which has aroused extensive research. However, as most of the existing methods do not achieve effective knowledge transfer to the target domain, they just fit the distribution of the seen slot and show poor performance on unseen slot in the target domain. To solve this, we propose a novel approach based on prototypical contrastive learning with a dynamic label confusion strategy for zero-shot slot filling. The prototypical contrastive learning aims to reconstruct the semantic constraints of labels, and we introduce the label confusion strategy to establish the label dependence between the source domains and the target domain on-the-fly. Experimental results show that our model achieves significant improvement on the unseen slots, while also set new state-of-the-arts on slot filling task.","tags":["\"Slot filling\""],"title":"Bridge to Target Domain by Prototypical Contrastive Learning and Label Confusion Re-explore Zero-Shot Learning for Slot Filling","type":"publication"},{"authors":["王礼文","严渊蒙","KeqingHe","吴亚楠","徐蔚然"],"categories":[],"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1614556800,"objectID":"b4f0a702fb1f1f8042fe315a418ee6c1","permalink":"https://pris-nlp.github.io/publication/dynamically-disentangling-social-bias-from-task-oriented-representations-with-adversarial-attack/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/dynamically-disentangling-social-bias-from-task-oriented-representations-with-adversarial-attack/","section":"publication","summary":"Representation learning is widely used in NLP for a vast range of tasks. However, representations derived from text corpora often reflect social biases. This phenomenon is pervasive and consistent across different neural models, causing serious concern. Previous methods mostly rely on a pre-specified, user-provided direction or suffer from unstable training. In this paper, we propose an adversarial disentangled debiasing model to dynamically decouple social bias attributes from the intermediate representations trained on the main task. We aim to denoise bias information while training on the downstream task, rather than completely remove social bias and pursue static unbiased representations. Experiments show the effectiveness of our method, both on the effect of debiasing and the main task performance.","tags":["\"Social Bias\"","\"Debias\""],"title":"Dynamically Disentangling Social Bias from Task-Oriented Representations with Adversarial Attack","type":"publication"},{"authors":["HongXu","KeqingHe","严渊蒙","SihongLiu","ZijunLiu","徐蔚然"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"c6801eecfd9d1668cc7b342e6d71f923","permalink":"https://pris-nlp.github.io/publication/a-deep-generative-distance-based-classifier-for-out-of-domain-detection-with-mahalanobis-space/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/a-deep-generative-distance-based-classifier-for-out-of-domain-detection-with-mahalanobis-space/","section":"publication","summary":"Zero-shot slot filling has widely arisen to cope with data scarcity in target domains. However, previous approaches often ignore constraints between slot value representation and related slot description representation in the latent space and lack enough model robustness. In this paper, we propose a Contrastive Zero-Shot Learning with Adversarial Attack (CZSL-Adv) method for the cross-domain slot filling. The contrastive loss aims to map slot value contextual representations to the corresponding slot description representations. And we introduce an adversarial attack training strategy to improve model robustness. Experimental results show that our model significantly outperforms state-of-the-art baselines under both zero-shot and few-shot settings.","tags":["\"OOD\"","\"intent detection\""],"title":"A Deep Generative Distance-Based Classifier for Out-of-Domain Detection with Mahalanobis Space","type":"publication"},{"authors":["KeqingHe","严渊蒙","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"c477c292e6854b6702d1eb514b4230f7","permalink":"https://pris-nlp.github.io/publication/adversarial-cross-lingual-transfer-learning-for-slot-tagging-of-low-resource-languages/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/adversarial-cross-lingual-transfer-learning-for-slot-tagging-of-low-resource-languages/","section":"publication","summary":"Slot tagging is a key component in a task-oriented dialogue system. Conversational agents need to understand human input by training on large amounts of annotated data. However, most human languages are low-resource and lack annotated training data for slot tagging task. Therefore, we aim to leverage cross-lingual transfer learning from high-resource languages to low-resource ones. In this paper, we propose an adversarial cross-lingual transfer model with multi-level language shared and specific knowledge to improve the slot tagging task of low-resource languages. Our method explicitly separates the model into the language-shared part and language-specific part to transfer language-independent knowledge. To refine shared knowledge in the latent space, we add a language discriminator and employ adversarial training to reinforce feature separation. Besides, we adopt a novel multi-level feature transfer in an incremental and progressive way to acquire multi-granularity shared knowledge. To mitigate the discrepancies between the feature distributions of language specific and shared knowledge, we propose the neural adapters to fuse features from different sources. Experiments show that our proposed model consistently outperforms monolingual baseline with a statistically significant margin up to 2.09%, even higher improvement of 12.21% in the zero-shot setting. Further analysis demonstrates that our method could effectively alleviate data scarcity of low-resource languages.","tags":["\"genetic algorithm\"","\"heterogeneous multiprocessor scheduling\"","\"memetic algorithm\"","\"variable neighborhood search\""],"title":"Adversarial Cross-Lingual Transfer Learning for Slot Tagging of Low-Resource Languages","type":"publication"},{"authors":["ZhiyuanZeng","KeqingHe","严渊蒙","HongXu","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"482f1bd9d93aed37194f0973986c3c4d","permalink":"https://pris-nlp.github.io/publication/adversarial-self-supervised-learning-for-out-of-domain-detection/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/adversarial-self-supervised-learning-for-out-of-domain-detection/","section":"publication","summary":"","tags":["\"OOD\"","\"intent detection\""],"title":"Adversarial Self-Supervised Learning for Out-of-Domain Detection","type":"publication"},{"authors":["严渊蒙","KeqingHe","HongXu","SihongLiu","FanyuMeng","MinHu","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"c75348ca95a9866f3643a784a745dc4a","permalink":"https://pris-nlp.github.io/publication/adversarial-semantic-decoupling-for-recognizing-open-vocabulary-slots/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/adversarial-semantic-decoupling-for-recognizing-open-vocabulary-slots/","section":"publication","summary":"Open-vocabulary slots, such as file name, album name, or schedule title, significantly degrade the performance of neural-based slot filling models since these slots can take on values from a virtually unlimited set and have no semantic restriction nor a length limit. In this paper, we propose a robust adversarial model-agnostic slot filling method that explicitly decouples local semantics inherent in open-vocabulary slot words from the global context. We aim to depart entangled contextual semantics and focus more on the holistic context at the level of the whole sentence. Experiments on two public datasets show that our method consistently outperforms other methods with a statistically significant margin on all the open-vocabulary slots without deteriorating the performance of normal slots.","tags":["\"Slot Filling\""],"title":"Adversarial Semantic Decoupling for Recognizing Open-Vocabulary Slots","type":"publication"},{"authors":["严渊蒙","RumeiLi","SiruiWang","FuzhengZhang","WeiWu","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"d17ed1832a6b7f76a113da7a17518417","permalink":"https://pris-nlp.github.io/publication/consert-a-contrastive-framework-for-self-supervised-sentence-representation-transfer/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/consert-a-contrastive-framework-for-self-supervised-sentence-representation-transfer/","section":"publication","summary":"Learning high-quality sentence representations benefits a wide range of natural language processing tasks. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the native derived sentence representations are proved to be collapsed and thus produce a poor performance on the semantic textual similarity (STS) tasks. In this paper, we present ConSERT, a Contrastive Framework for Self-Supervised SEntence Representation Transfer, that adopts contrastive learning to fine-tune BERT in an unsupervised and effective way. By making use of unlabeled texts, ConSERT solves the collapse issue of BERT-derived sentence representations and make them more applicable for downstream tasks. Experiments on STS datasets demonstrate that ConSERT achieves an 8\\% relative improvement over the previous state-of-the-art, even comparable to the supervised SBERT-NLI. And when further incorporating NLI supervision, we achieve new state-of-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios.","tags":["\"Semantic Textual Similarity\""],"title":"ConSERT A Contrastive Framework for Self-Supervised Sentence Representation Transfer","type":"publication"},{"authors":["KeqingHe","JinchaoZhang","严渊蒙","徐蔚然","ChengNiu","JieZhou"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"d2894e19605efc452a5ff05186792a64","permalink":"https://pris-nlp.github.io/publication/contrastive-zero-shot-learning-for-cross-domain-slot-filling-with-adversarial-attack/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/contrastive-zero-shot-learning-for-cross-domain-slot-filling-with-adversarial-attack/","section":"publication","summary":"Zero-shot slot filling has widely arisen to cope with data scarcity in target domains. However, previous approaches often ignore constraints between slot value representation and related slot description representation in the latent space and lack enough model robustness. In this paper, we propose a Contrastive Zero-Shot Learning with Adversarial Attack (CZSL-Adv) method for the cross-domain slot filling. The contrastive loss aims to map slot value contextual representations to the corresponding slot description representations. And we introduce an adversarial attack training strategy to improve model robustness. Experimental results show that our model significantly outperforms state-of-the-art baselines under both zero-shot and few-shot settings.","tags":["\"Slot Filling\""],"title":"Contrastive Zero-Shot Learning for Cross-Domain Slot Filling with Adversarial Attack","type":"publication"},{"authors":["KeqingHe","严渊蒙","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"370fcbc724df4459ab28ea34406f0218","permalink":"https://pris-nlp.github.io/publication/from-context-aware-to-knowledge-aware-boosting-oov-tokens-recognition-in-slot-tagging-with-background-knowledge/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/from-context-aware-to-knowledge-aware-boosting-oov-tokens-recognition-in-slot-tagging-with-background-knowledge/","section":"publication","summary":"Neural-based context-aware models for slot tagging tasks in language understanding have achieved state-of-the-art performance, especially deep contextualized models, such as ELMo, BERT. However, the presence of out-of-vocab (OOV) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-aware slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multi-level graph attention to explicitly reason via lexical relations. We aim to leverage both linguistic regularities covered by deep language models (LM) and high-quality background knowledge derived from curated knowledge bases (KB). Consequently, our model could infer rare and unseen words in the test dataset by incorporating contextual semantics learned from the training dataset and lexical relations from ontology. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets. We also show through detailed analysis that incorporating background knowledge effectively alleviates issues of data scarcity.","tags":["\"Slot taggingContextual\"","\"representationBackground\"","\"knowledgeKnowledge\"","\"IntegrationMulti-level\"","\"graph attention\""],"title":"From context-aware to knowledge-aware Boosting OOV tokens recognition in slot tagging with background knowledge","type":"publication"},{"authors":["LuluZhao","曾伟豪","徐蔚然","JunGuo"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"531badd442f99f521abe7590685d8731","permalink":"https://pris-nlp.github.io/publication/give-the-truth-incorporate-semantic-slot-into-abstractive-dialogue-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/give-the-truth-incorporate-semantic-slot-into-abstractive-dialogue-summarization/","section":"publication","summary":"Abstractive dialogue summarization suffers from a lots of factual errors, which are due to scattered salient elements in the multi-speaker information interaction process. In this work, we design a heterogeneous semantic slot graph with a slot-level mask cross-attention to enhance the slot features for more correct summarization. We also propose a slot-driven beam search algorithm in the decoding process to give priority to generating salient elements in a limited length by “filling-in-the-blanks”. Besides, an adversarial contrastive learning assisting the training process is introduced to improve the generalization of our model. Experimental performance on different types of factual errors shows the effectiveness of our methods and human evaluation further verifies the results.","tags":["\"Dialogue Summarization\""],"title":"Give the Truth Incorporate Semantic Slot into Abstractive Dialogue Summarization","type":"publication"},{"authors":["ZhiyuanZeng","JiazeChen","徐蔚然","LeiLi"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"012f1047329d4dc68a563f4b8fb07aa2","permalink":"https://pris-nlp.github.io/publication/gradient-based-adversarial-factual-consistency-evaluation-for-abstractive-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/gradient-based-adversarial-factual-consistency-evaluation-for-abstractive-summarization/","section":"publication","summary":"Neural abstractive summarization systems have gained significant progress in recent years. However, excessive abstractiveness inevitably leads to factual errors, which poses a challenge to the robustness of the systems. In this paper, we proposed an efficient weak-supervised adversarial data augmentation approach to form the factual consistency dataset. Based on the artificial dataset, we train an evaluation model that can not only make accurate and robust factual consistency discrimination but is also capable of making interpretable factual errors tracing by backpropagated gradient distribution on token embeddings. Experiments and analysis conduct on public annotated summarization and factual consistency datasets demonstrate our approach effective and reasonable.","tags":["\"Factual Consistency Evaluation\""],"title":"Gradient-Based Adversarial Factual Consistency Evaluation for Abstractive Summarization","type":"publication"},{"authors":["YuejieLei","严渊蒙","ZhiyuanZeng","KeqingHe","XimingZhang","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"24c52aa27079cad3f87ff08feb16ffcf","permalink":"https://pris-nlp.github.io/publication/hierarchical-speaker-aware-sequence-to-sequence-model-for-dialogue-summarization/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/hierarchical-speaker-aware-sequence-to-sequence-model-for-dialogue-summarization/","section":"publication","summary":"","tags":["\"Dialogue Summarization\""],"title":"Hierarchical Speaker-aware Sequence-to-sequence Model for Dialogue Summarization","type":"publication"},{"authors":["LuluZhao","徐蔚然","JunGuo"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"d1f0e2d750144bca0c36c4654540daef","permalink":"https://pris-nlp.github.io/publication/improving-abstractive-dialogue-summarization-with-graph-structures-and-topic-words/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/improving-abstractive-dialogue-summarization-with-graph-structures-and-topic-words/","section":"publication","summary":"Recently, people have been beginning paying more attention to the abstractive dialogue summarization task. Since the information flows are exchanged between at least two interlocutors and key elements about a certain event are often spanned across multiple utterances, it is necessary for researchers to explore the inherent relations and structures of dialogue contents. However, the existing approaches often process the dialogue with sequence-based models, which are hard to capture long-distance inter-sentence relations. In this paper, we propose a Topic-word Guided Dialogue Graph Attention (TGDGA) network to model the dialogue as an interaction graph according to the topic word information. A masked graph self-attention mechanism is used to integrate cross-sentence information flows and focus more on the related utterances, which makes it better to understand the dialogue. Moreover, the topic word features are introduced to assist the decoding process. We evaluate our model on the SAMSum Corpus and Automobile Master Corpus. The experimental results show that our method outperforms most of the baselines.","tags":["\"Dialogue Summarization\""],"title":"Improving Abstractive Dialogue Summarization with Graph Structures and Topic Words","type":"publication"},{"authors":["严渊蒙","RumeiLi","SiruiWang","HongzhiZhang","ZanDaoguang","FuzhengZhang","WeiWu","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"19f4ec05789a769e39f069d1d9dc707c","permalink":"https://pris-nlp.github.io/publication/large-scale-relation-learning-for-question-answering-over-knowledge-bases-with-pre-trained-language-models/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/large-scale-relation-learning-for-question-answering-over-knowledge-bases-with-pre-trained-language-models/","section":"publication","summary":"The key challenge of question answering over knowledge bases (KBQA) is the inconsistency between the natural language questions and the reasoning paths in the knowledge base (KB). Recent graph-based KBQA methods are good at grasping the topological structure of the graph but often ignore the textual information carried by the nodes and edges. Meanwhile, pre-trained language models learn massive open-world knowledge from the large corpus, but it is in the natural language form and not structured. To bridge the gap between the natural language and the structured KB, we propose three relation learning tasks for BERT-based KBQA, including relation extraction, relation matching, and relation reasoning. By relation-augmented training, the model learns to align the natural language expressions to the relations in the KB as well as reason over the missing connections in the KB. Experiments on WebQSP show that our method consistently outperforms other baselines, especially when the KB is incomplete.","tags":["\"KBQA\""],"title":"Large-Scale Relation Learning for Question Answering over Knowledge Bases with Pre-trained Language Models","type":"publication"},{"authors":["KeqingHe","严渊蒙","HongXu","SihongLiu","ZijunLiu","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"bbc3080227b4a6c079b736aa826676b2","permalink":"https://pris-nlp.github.io/publication/learning-label-relational-output-structure-for-adaptive-sequence-labeling/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/learning-label-relational-output-structure-for-adaptive-sequence-labeling/","section":"publication","summary":"Sequence labeling is a fundamental task of natural language understanding. Recent neural models for sequence labeling task achieve significant success with the availability of sufficient training data. However, in practical scenarios, entity types to be annotated even in the same domain are continuously evolving. To transfer knowledge from the source model pre-trained on previously annotated data, we propose an approach which learns label-relational output structure to explicitly capturing label correlations in the latent space. Additionally, we construct the target-to-source interaction between the source model M S and the target model M T and apply a gate mechanism to control how much information in M S and M T should be passed down. Experiments show that our method consistently outperforms the state-of-the-art methods with a statistically significant margin and effectively facilitates to recognize rare new entities in the target data especially.","tags":["\"adaptive sequence labeling\"","\"transfer learning\"","\"label-relational output structure\"","\"latent space\""],"title":"Learning Label-Relational Output Structure for Adaptive Sequence Labeling","type":"publication"},{"authors":["KeqingHe","严渊蒙","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"086ca0957f4abebb8754d1f4bff90ab3","permalink":"https://pris-nlp.github.io/publication/learning-to-tag-oov-tokens-by-integrating-contextual-representation-and-background-knowledge/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/learning-to-tag-oov-tokens-by-integrating-contextual-representation-and-background-knowledge/","section":"publication","summary":"Neural-based context-aware models for slot tagging have achieved state-of-the-art performance. However, the presence of OOV(out-of-vocab) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-enhanced slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multi-level graph attention to explicitly model lexical relations. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets.","tags":["\"Slot Filling\""],"title":"Learning to Tag OOV Tokens by Integrating Contextual Representation and Background Knowledge","type":"publication"},{"authors":["ZhiyuanZeng","KeqingHe","严渊蒙","ZijunLiu","吴亚楠","HongXu","HuixingJiang","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"f3ebe8e02e929c931daa39b8b5a87907","permalink":"https://pris-nlp.github.io/publication/modeling-discriminative-representations-for-out-of-domain/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/modeling-discriminative-representations-for-out-of-domain/","section":"publication","summary":"Detecting Out-of-Domain (OOD) or unknown intents from user queries is essential in a task oriented dialog system. A key challenge of OOD detection is to learn discriminative se mantic features. Traditional cross-entropy loss only focuses on whether a sample is correctly classified, and does not explicitly distinguish the margins between categories. In this pa per, we propose a supervised contrastive learn ing objective to minimize intra-class variance by pulling together in-domain intents belong ing to the same class and maximize inter-class variance by pushing apart samples from differ ent classes. Besides, we employ an adversar ial augmentation mechanism to obtain pseudo diverse views of a sample in the latent space. Experiments on two public datasets prove the effectiveness of our method capturing discrim inative representations for OOD detection.","tags":["\"OOD\"","\"intent detection\""],"title":"Modeling Discriminative Representations for Out-of-Domain Detection with Supervised Contrastive Learning","type":"publication"},{"authors":["吴亚楠","ZhiyuanZeng","KeqingHe","HongXu","严渊蒙","HuixingJiang","徐蔚然"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"b4a06f42b461c513bbb4e5bf80a038dd","permalink":"https://pris-nlp.github.io/publication/novel-slot-detection-a-benchmark-for-discovering-unknown-slot-types/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/novel-slot-detection-a-benchmark-for-discovering-unknown-slot-types/","section":"publication","summary":"Existing slot filling models can only recognize pre-defined in-domain slot types from a limited slot set. In the practical application, a reliable dialogue system should know what it does not know. In this paper, we introduce a new task, Novel Slot Detection (NSD), in the task-oriented dialogue system. NSD aims to discover unknown or out-of-domain slot types to strengthen the capability of a dialogue system based on in-domain training data. Besides, we construct two public NSD datasets propose several strong NSD baselines, and establish a benchmark for future work. Finally, we conduct exhaustive experiments and qualitative analysis to comprehend key challenges and provide new guidance for future directions","tags":["\"OOD\"","\"intent detection\""],"title":"Novel Slot Detection A Benchmark for Discovering Unknown Slot Types in the Task-Oriented Dialogue System","type":"publication"},{"authors":["SihongLiu","JinchaoZhang","KeqingHe,","徐蔚然","JieZhou"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"25a89a2bccac6ffea3953c05b415c1d6","permalink":"https://pris-nlp.github.io/publication/scheduled-dialog-policy-learning-an-automatic-curriculum-learning-framework-for-task-oriented-dialog-system/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/scheduled-dialog-policy-learning-an-automatic-curriculum-learning-framework-for-task-oriented-dialog-system/","section":"publication","summary":"","tags":["\"dialog management\""],"title":"Scheduled Dialog Policy Learning An Automatic Curriculum Learning Framework for Task-oriented Dialog System","type":"publication"},{"authors":["LuluZhao","徐蔚然","ShengGao","JunGuo"],"categories":[],"content":"","date":1600523751,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"c0c28cf3e1a16d838b506f7e58e34c35","permalink":"https://pris-nlp.github.io/publication/utilizing-graph-neural-networks-to-improving-dialogue-based-relation-extraction/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/utilizing-graph-neural-networks-to-improving-dialogue-based-relation-extraction/","section":"publication","summary":"Relation extraction has been an active research interest in the field of Natural Language Processing (NLP). The past works primarily focused on a corpus of formal text which is inherently non-dialogic. Recently, the dialogue-based relation extraction task, which detects relations among speaker-aware entities scattering in dialogues, has been gradually arousing people’s attention. Some sequence-based neural methods have been carried out to obtain the relevant information. However, identifying cross-sentence relations remains unsolved, especially in the context of a specific-domain dialogue system. In this paper, we propose a Relational Attention Enhanced Graph Convolutional Network (RAEGCN), which constructs the whole dialogue as a semantic interactive graph by emphasizing the speaker-related information and leveraging various inter-sentence dependencies. A dense connectivity mechanism is also introduced to empower the multi-hop relational reasoning across sentences, which can capture both local and non-local features simultaneously. Experiments show the significant superiority and robustness of our model on a real-world dataset DialogRE, as compared with previous approaches.","tags":["\"Dialogue Relation Extraction \""],"title":"Utilizing Graph Neural Networks to Improving Dialogue-based Relation Extraction","type":"publication"},{"authors":["YuanyuanQi","JiayueZhang","YansongLiu","徐蔚然","JunGuo"],"categories":[],"content":"","date":1600473600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600523752,"objectID":"3a052120ec6fb7d2864d896b363f3f70","permalink":"https://pris-nlp.github.io/publication/cgtr-convolution-graph-topology-representation-for-document-ranking/","publishdate":"2020-09-19T13:55:51.366191Z","relpermalink":"/publication/cgtr-convolution-graph-topology-representation-for-document-ranking/","section":"publication","summary":"Contextualized neural language models have gained much attention in Information Retrieval (IR) with its ability to achieve better text understanding by capturing contextual structure. However, to achieve better document understanding, it is necessary to involve global structure of a document. In this paper, we take the advantage of Graph Convolutional Networks (GCN) to model global word-relation structure of a document to improve context-aware document ranking. We propose to build a graph for a document to model the global structure. The nodes and edges of the graph are constructed from contextual embeddings. Then we apply graph convolution on the graph to learning a new representation, and this representation covers both contextual and global structure information. The experimental results show that our method outperforms the state-of-the-art contextual language models, which demonstrate that incorporating global structure is useful for improving document ranking and GCN is an effective way to achieve it.","tags":["\"Text Understanding\"","\"Contextualized Neural Language Models\"","\"Graph\"","\"Convolution Networks\""],"title":"CGTR:Convolution Graph Topology Representation for Document Ranking","type":"publication"},{"authors":["PengdaQin","XinWang","WenhuChen","ChunyunZhang","徐蔚然","WilliamYangWang"],"categories":[],"content":"","date":1585872000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1600522724,"objectID":"d46e35e66847a328424370fdd170fc76","permalink":"https://pris-nlp.github.io/publication/generative-adversarial-zero-shot-relation-learning-for-knowledge-grapths/","publishdate":"2020-09-19T13:38:44.301342Z","relpermalink":"/publication/generative-adversarial-zero-shot-relation-learning-for-knowledge-grapths/","section":"publication","summary":"Large-scale knowledge graphs (KGs) are shown to become more important in current information systems. To expand the coverage of KGs, previous studies on knowledge graph completion need to collect adequate training instances for newly-added relations. In this paper, we consider a novel formulation, zero-shot learning, to free this cumbersome curation. For newly-added relations, we attempt to learn their semantic features from their text descriptions and hence recognize the facts of unseen relations with no examples being seen. For this purpose, we leverage Generative Adversarial Networks (GANs) to establish the connection between text and knowledge graph domain:The generator learns to generate the reasonable relation embeddings merely with noisy text descriptions. Under this setting, zero-shot learning is naturally converted to a traditional supervised classification task. Empirically, our method is model-agnostic that could be potentially applied to any version of KG embeddings, and consistently yields performance improvements on NELL and Wiki dataset.","tags":["\"Knowledge Graph Completion\""],"title":"Generative Adversarial Zero-Shot Relation Learning for Knowledge Grapths","type":"publication"},{"authors":["HuaXu"],"categories":null,"content":"课程类型：清华大学公选课\n主讲教师：徐华\n授课对象：全校本科生\n授课时间：2019 - 今\n","date":1546272000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546272000,"objectID":"407bfb7ec4580d302372641bb7e5039e","permalink":"https://pris-nlp.github.io/talk/internet-product-design/","publishdate":"2019-01-01T00:00:00+08:00","relpermalink":"/talk/internet-product-design/","section":"talk","summary":"清华大学公选课","tags":[],"title":"《互联网产品设计》","type":"talk"},{"authors":["HuaXu"],"categories":null,"content":"课程类型：清华大学公选课\n主讲教师：徐华\n授课对象：全校本科生\n授课时间：2016-今\n","date":1451577600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1451577600,"objectID":"050eb509d73d451227a478cbd25c314e","permalink":"https://pris-nlp.github.io/talk/intelligent-mobile-robot/","publishdate":"2016-01-01T00:00:00+08:00","relpermalink":"/talk/intelligent-mobile-robot/","section":"talk","summary":"清华大学公选课","tags":[],"title":"《智能移动机器人：设计、编程与实践》","type":"talk"},{"authors":["HuaXu"],"categories":null,"content":"课程类型：清华大学公选课\n主讲教师：徐华\n授课对象：全校本科生、研究生\n授课时间：2013 - 今\n","date":1356969600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1356969600,"objectID":"e7d4ecfaf4b1f29cd65dd9ec01f1f6ad","permalink":"https://pris-nlp.github.io/talk/industrial-data-mining/","publishdate":"2013-01-01T00:00:00+08:00","relpermalink":"/talk/industrial-data-mining/","section":"talk","summary":"清华大学公选课","tags":[],"title":"《工业数据挖掘》","type":"talk"},{"authors":["HuaXu"],"categories":null,"content":"课程类型：清华大学公选课\n主讲教师：徐华\n授课对象：全校本科生\n授课时间：2011 - 今\n","date":1293811200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1293811200,"objectID":"3e7631952ecff1e05471581a1af8e97d","permalink":"https://pris-nlp.github.io/talk/data-mining-method-and-application/","publishdate":"2011-01-01T00:00:00+08:00","relpermalink":"/talk/data-mining-method-and-application/","section":"talk","summary":"清华大学公选课","tags":[],"title":"《数据挖掘：方法与应用》","type":"talk"},{"authors":["JunhuiDeng"],"categories":null,"content":"课程类型：清华大学计算机系本科生专业基础课\n主讲教师：邓俊辉\n授课对象：全校本科生\n授课时间：2001 - 2006\n","date":978278400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":978278400,"objectID":"b7caabb0e4bde45ecc0519114b6a051c","permalink":"https://pris-nlp.github.io/talk/data-structure-cs/","publishdate":"2001-01-01T00:00:00+08:00","relpermalink":"/talk/data-structure-cs/","section":"talk","summary":"清华大学计算机系本科生专业基础课","tags":[],"title":"《数据结构》","type":"talk"},{"authors":["JunhuiDeng"],"categories":null,"content":"课程类型：清华大学公选课\n主讲教师：邓俊辉\n授课对象：全校本科生\n授课时间：2002 - 今\n","date":978278400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":978278400,"objectID":"970c56d891d3e1abdca0aaf1b5140c8d","permalink":"https://pris-nlp.github.io/talk/data-structure/","publishdate":"2001-01-01T00:00:00+08:00","relpermalink":"/talk/data-structure/","section":"talk","summary":"国家级精品课 清华大学公选课","tags":[],"title":"《数据结构》","type":"talk"},{"authors":["JunhuiDeng","HuaXu"],"categories":null,"content":"课程类型：清华大学计算机系研究生基础理论课\n主讲教师：邓俊辉，徐华\n授课对象：全校研究生\n授课时间：1997 - 今\n","date":852048000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":852048000,"objectID":"f93308c8be1670e9b2dc795f64282a4a","permalink":"https://pris-nlp.github.io/talk/computational-geometry/","publishdate":"1997-01-01T00:00:00+08:00","relpermalink":"/talk/computational-geometry/","section":"talk","summary":"清华大学计算机系研究生基础理论课","tags":[],"title":"《计算几何》","type":"talk"},{"authors":["ShiningFu","YuOuJiang","SongYanLiu","ZongaiXie"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"81cfb197ded20cb72e29f2b0f2d75a31","permalink":"https://pris-nlp.github.io/project/cqa%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/cqa%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","section":"project","summary":"社区问答（community question answering, CQA）在近些年得到了广泛关注，随着百度知道、知乎、搜狗问问、Stack Overflow等社区问答网站的出现，越来越多的人选择网络社区来获取答案。CQA与一般QA任务的不同在于问题和答案是开放领域的，通常较长，包含多个句子，文本不是结构化的，且含有大量噪音。一般的CQA系统构建步骤如下：a)用搜索引擎比如Lucene先离线构建问题-答案对的索引；b)在线收到query后，初步召回一组候选答案构成的集合；c)用文本匹配算法和排序算法对候选答案重新排序并返回最佳答案。","tags":[],"title":"CQA系统设计与实现","type":"project"},{"authors":["XiusenGu","ChenDing"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"810a5371f9a51746b57fcc1908de410b","permalink":"https://pris-nlp.github.io/project/%E4%B8%8D%E8%89%AF%E8%8D%AF%E7%89%A9%E5%8F%8D%E5%BA%94%E6%8A%BD%E5%8F%96%E8%AF%84%E6%B5%8B/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E4%B8%8D%E8%89%AF%E8%8D%AF%E7%89%A9%E5%8F%8D%E5%BA%94%E6%8A%BD%E5%8F%96%E8%AF%84%E6%B5%8B/","section":"project","summary":"该评测主要对药品说明书中进行不良药物反应的实体抽取和关系抽取两个子任务，其中实体抽取以BiLSTM-CRF为主要模型，并融合了词向量和字向量作为表征；关系抽取针对标注语料少的问题，采用了对抗噪声的方法作为数据增强的手段。","tags":[],"title":"不良药物反应抽取评测","type":"project"},{"authors":["JingboShi","SongyanLiu","YuejieLei","ZhiyuanZeng","严渊蒙","郑馥嘉","李雪峰"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"c6f8ce4e98dbc35bc3179674f3802755","permalink":"https://pris-nlp.github.io/project/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BB%BA%E8%AE%BE%E9%A1%B9%E7%9B%AE%E8%BF%90%E7%BB%B4%E7%9F%A5%E8%AF%86%E5%AD%90%E4%BB%BB%E5%8A%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BB%BA%E8%AE%BE%E9%A1%B9%E7%9B%AE%E8%BF%90%E7%BB%B4%E7%9F%A5%E8%AF%86%E5%AD%90%E4%BB%BB%E5%8A%A1/","section":"project","summary":"该项目针对的场景是客服为用户进行运维工作后，针对已形成的工单，从中获得按照故障原因以及解决措施的形式的运维知识，并且结构化表示运维知识以形成一个运维知识库；即该项目分为两部分，一部分是运维知识挖掘系统，另一部分是运维知识库的构建。","tags":[],"title":"人工智能建设项目——运维知识子任务","type":"project"},{"authors":["JingboShi","SongyanLiu","ZongaiXie","YufengLi","JianingZhang","ZhiyuanZeng","YuejieLei","JinzhengZhao","郑馥嘉"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"74b30f4cfe76e1cd8e1fbeccc8fa6ab1","permalink":"https://pris-nlp.github.io/project/%E4%BC%9A%E8%AE%AE%E5%9C%BA%E6%99%AF%E8%87%AA%E5%8A%A8%E6%91%98%E8%A6%81%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E4%BC%9A%E8%AE%AE%E5%9C%BA%E6%99%AF%E8%87%AA%E5%8A%A8%E6%91%98%E8%A6%81%E7%B3%BB%E7%BB%9F/","section":"project","summary":"该项目应用在多人会议场景，主要通过会议整体内容提炼以及各发言者主要观点总结，形成篇幅较短但涵盖主要信息的生成式会议摘要。通过阅读摘要能够在短时间内形成对会议内容以及个人观点的大体认知，有效提高了多人协作过程中理解和沟通的效率。系统整体建立在无监督的基础上，主要通过大规模预训练语言模型在资源相对丰富的新闻摘要数据集上进行微调后，迁移至会议场景进行生成式摘要任务。考虑到场景之间的差异，通过自监督方法对生成的摘要进行风格迁移，使之具备更佳的可读性。设计了发言者画像库，用于收集和使用代表性的个人发言，以更好的表征语言习惯、关注点等个人特征，促进模型更精确和高效的定位关键信息。","tags":[],"title":"会议场景自动摘要系统","type":"project"},{"authors":["KeqingHe","HongXu","SihongLiu","严渊蒙","ZijunLiu"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"47f4f1bd642991a4303782c9988dd74e","permalink":"https://pris-nlp.github.io/project/%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E7%B3%BB%E7%BB%9F/","section":"project","summary":"在线教育场景下通过人机对话的方式来完成特定的任务，主要包括以下三个方面：自然语言理解（NLU）：包括领域识别、意图识别、槽位提取三个子模块。通过领域识别的输出触发不同的场景，由意图识别和槽位提取将自然语言转换成系统可以理解的结构化表示。对话管理（DM）：包括对话状态追踪和对话策略两个部分。对话状态追踪根据用户输入的结构化表示和历史对话信息，更新当前的对话状态；对话策略模块根据当前的对话状态和用户输入的结构化表示进行决策，输出系统回复的结构化表示。自然语言生成（NLG）：将系统输出的结构化表示转化为自然语言输出。","tags":[],"title":"在线教育场景下的智能客服系统","type":"project"},{"authors":["XiusenGu","YanLi"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"5b3b76480963135db9c98f01a3746bc4","permalink":"https://pris-nlp.github.io/project/%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/","section":"project","summary":"利用实体识别和关系抽取技术，从百度搜索返回的候选结果中抽取答案实体返回。可识别预定义的10种关系。项目中的关系抽取采用了TextCNN、SVM和模板匹配三种模型，并根据模型的置信度进行了集成。","tags":[],"title":"基于搜索引擎的问答系统","type":"project"},{"authors":["JiandongSun","XiusenGu","ChenliangLi","ChenDing","YanLi","YifanWang","XinyuanLi"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"446e2def38c930807628d2de922f952a","permalink":"https://pris-nlp.github.io/project/%E5%A4%9A%E6%BA%90%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%91%E8%B0%B1%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E5%A4%9A%E6%BA%90%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%91%E8%B0%B1%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/","section":"project","summary":"针对各种无线通信技术构建频谱知识图谱。知识图谱，是结构化的语义知识库，用于迅速描述物理世界中的概念及其相互关系，通过将数据粒度从document级别降到data级别，聚合大量知识，从而实现知识的快速响应和推理。知识图谱技术与各行业的深度融合已经成为一个重要趋势。该知识图谱将被用于实际信号的仿真，分离和识别。","tags":[],"title":"多源多模态频谱知识图谱","type":"project"},{"authors":["ChaoZhang","XiongxiYu","PuWang","BaohangZhan","JialeHong","KeqingHe","HongXu","SihongLiu"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"114f2d8ce970d0a4a871bf632f5e58da","permalink":"https://pris-nlp.github.io/project/%E5%A4%9A%E8%BD%AE%E6%9C%BA%E7%A5%A8%E9%A2%84%E8%AE%A2%E6%9F%A5%E8%AF%A2%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E5%A4%9A%E8%BD%AE%E6%9C%BA%E7%A5%A8%E9%A2%84%E8%AE%A2%E6%9F%A5%E8%AF%A2%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"project","summary":"以机票的预订以及查询为任务背景，构建的特定任务的多轮对话系统。其主要模块分为自然语言处理（NLU），对话管理（DM），自然语言生成（NLG），机票知识库，并通过PIPELINE的形式进行连接构成整个系统。其中NLU模块中的意图识别、实体识别；DM模块中的策略决策，均采用当前最新的神经网络模型得到，同时也为模型的泛化，提供可能。","tags":[],"title":"多轮机票预订查询对话系统","type":"project"},{"authors":["KeqingHe","SihongLiu","HongXu","严渊蒙","ZijunLiu","王礼文","吴亚楠"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"275fdff6079688df969792546513cdc3","permalink":"https://pris-nlp.github.io/project/%E5%AD%A6%E5%91%98%E5%9F%B9%E8%AE%AD%E6%A8%A1%E6%8B%9F%E7%94%A8%E6%88%B7%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E5%AD%A6%E5%91%98%E5%9F%B9%E8%AE%AD%E6%A8%A1%E6%8B%9F%E7%94%A8%E6%88%B7%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"project","summary":"该项目的落地场景为保险行业销售员培训系统，其中本项目的对话系统担任模拟客户的角色，通过和真实学员的对话交互来对学员的语言表述进行打分，借此提高保险销售学员的业务能力。整体对话系统采用经典管道结构，分为自然语言理解、对话管理和自然语言生成三个部分。其中自然语言处理除了基本的实体意图识别还加入了多意图识别的考量，对话管理部分采用分流程分阶段控制对话的规则设定。在项目后期，整体会加入情感分析，即学员的表达中蕴含的情感因素也会成为打分的评分点。","tags":[],"title":"学员培训模拟用户对话系统","type":"project"},{"authors":["JingboShi","SongyanLiu","ZongaiXie","YufengLi","JianingZhang","YujieLei","ZhiyuanZeng","郑馥嘉","李雪峰"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"cb93aadb9f4c3912d2b775e5e6faec7b","permalink":"https://pris-nlp.github.io/project/%E5%B7%A5%E5%8D%95%E5%AF%B9%E8%AF%9D%E6%91%98%E8%A6%81%E9%A1%B9%E7%9B%AE/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E5%B7%A5%E5%8D%95%E5%AF%B9%E8%AF%9D%E6%91%98%E8%A6%81%E9%A1%B9%E7%9B%AE/","section":"project","summary":"该项目针对场景是用户与客服进行电话咨询，系统通过用户与客服之间的多轮对话通过摘要的方法生成相应的用户提出的问题以及客服给出的诊断以及解决方案的自然语言文本作为该次会话的工单记录。","tags":[],"title":"工单对话摘要项目","type":"project"},{"authors":["ChunyuMa","YufeiShen","JingboShi"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"bbb232daa62fc5e164cf68d426c654f3","permalink":"https://pris-nlp.github.io/project/%E6%83%85%E6%84%9F%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E6%83%85%E6%84%9F%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"project","summary":"本项目针对闲聊领域中情感对话的生成，旨在设计并实现一个能理解用户输入情感并给出恰当情感回复的聊天机器人。具体功能被划分为三个部分，首先需要充分理解用户输入所包含的情感；其实需要根据用户的输入情感计算出回复时应该包含的情感；最后根据用户输入生成一句包含目标情感的回复。","tags":[],"title":"情感对话系统","type":"project"},{"authors":["KeqingHe","SongYan","HongXu","SihongLiu","严渊蒙"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"361f03249fe398e87969a62e88960cb0","permalink":"https://pris-nlp.github.io/project/%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E8%B4%A8%E6%A3%80%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E8%B4%A8%E6%A3%80%E7%B3%BB%E7%BB%9F/","section":"project","summary":"针对某银行大型呼叫中心产生的海量非结构化录音内容进行自动化检测、分析和挖掘，极大地提升传统人工质检的效率与准确率，充分利用数据本身的价值信息。\n","tags":[],"title":"智能语音质检系统","type":"project"},{"authors":["ChaoZhang","XingxiYu","PuWang","BohangZhan","JialeHong","KeqingHe","HongXu","SihongLiu"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"288a0111f80c9908da59d6c1bfd1482c","permalink":"https://pris-nlp.github.io/project/%E7%89%B9%E5%AE%9A%E6%8A%A5%E4%BF%AE%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E7%89%B9%E5%AE%9A%E6%8A%A5%E4%BF%AE%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"project","summary":"系统最大的特点在于系统中各个模块的设置均可采用加载配置文件的方法来完成，同时加载不同领域的配置文件可以完成不同领域对话系统的切换。","tags":[],"title":"特定报修场景下的多轮对话系统","type":"project"},{"authors":["JiandongSun","ChenliangLi","WeijieLiu","ShiningPu","YuouJiang","BaohangZhan","XiongxiYu","JialeHong","KeqingHe","HongXu","SihongLiu","ZijunLiu"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"c869831e135fbffc2412cdf832caa827","permalink":"https://pris-nlp.github.io/project/%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/","section":"project","summary":"实现一个具有 QA 功能的知识搜索引擎。 该知识搜索引擎需要具有以下七个功能：                  – 计算:四则运算、费用计算、单位换算等; – 日历:跟日期、日期、干支等相关的提问;– 时间:问及日本及世界各地时刻的提问 – 定义:关于某一事物的定义提问 – 天气：关于天气进行提问 – 联想:由某个词语联想出来的事物 – 事实型:通过简短的语言来寻求简介回答的提问","tags":[],"title":"知识库问答系统","type":"project"},{"authors":["XiusenGu","ChenDing","ChaoZhang","ChunyuMa","PuWang"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"780c38932d9d87ec97af98e4dea3be9d","permalink":"https://pris-nlp.github.io/project/%E9%97%B2%E8%81%8A%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E9%97%B2%E8%81%8A%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/","section":"project","summary":"本系统包括三个垂直领域的任务型对话和闲聊对话，采用模块分层解耦设计，并配有聊天界面，是一个较完整、具备扩展性的智能对话系统。具体地，系统主要分为自然语言理解（NLU）模块、对话管理（DM）、自然语言生成（NLG）模块和前端界面四个模块。三个垂直领域包括电子产品、城市、明星，各个垂直领域会针对性地设置不同任务对话。项目中遇到了闲聊对话中的对话多样性问题，尝试利用了条件变分自动编码器；探索了情感在闲聊对话中的引入；在NLU的情感识别时，遇到了多分类问题中的数据不均衡问题，采用采样法、损失函数加权等方法缓解。","tags":[],"title":"闲聊对话系统","type":"project"},{"authors":["XiusenGu","ChenDing"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"73c8ac978bb9d06c337931368d65ee3b","permalink":"https://pris-nlp.github.io/project/%E9%9D%A2%E5%90%912022%E5%86%AC%E6%AE%8B%E5%A5%A5%E8%A7%86%E9%9A%9C%E4%BA%BA%E7%BE%A4%E7%9A%84%E5%A4%9A%E8%BD%AE%E4%BA%BA%E6%9C%BA%E5%AF%B9%E8%AF%9D%E4%B8%8E%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/%E9%9D%A2%E5%90%912022%E5%86%AC%E6%AE%8B%E5%A5%A5%E8%A7%86%E9%9A%9C%E4%BA%BA%E7%BE%A4%E7%9A%84%E5%A4%9A%E8%BD%AE%E4%BA%BA%E6%9C%BA%E5%AF%B9%E8%AF%9D%E4%B8%8E%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/","section":"project","summary":"针对视障人群的多轮人机对话与情感分析系统以知识库问答（ KBQA）、社区问答（CQA） 以及Web 搜索相关结果为知识来源，为残障人士提供导航帮助。如下图所示，其可以抽象为一个金字塔结构，金字塔的基石是底层知识库，来自KBQA 、CQA 和 Web 网页搜索；以底层知识库为支撑，在第二层构建一个具有情感分析、支持多轮对话的对话系统，实现系统具体功能；在具体功能层之上，进一步实现顶层交互模块，完成语音识别和语音合成等工作，与用户交互对话。三层金字塔结构逐层递进，协调合作，共同完成整体目标任务。\n\n为了满足服务冬奥会中视障人群快速问答的需求，系统核心技术主要包括四部分，如下图所示：\n\n1.（天蓝部分）第一部分是直接面向用户的是语音识别和语音合成模块，它们使得残障人士可以通过“说”和“听”的形式与系统进行交互，更加自然、便捷、无障碍；\n\n2.（绿色部分）第二部分是系统的情绪功能，分为情绪识别和情绪应答模块，它们使得我们的系统可以感知用户的情绪，并作出不同的应答，以顺应、安抚用户的情绪，让用户获得更好的使用体验；\n\n3.（灰蓝部分）第三部分是系统获取知识、作出回答的核心模块，包括知识库问答、互联网信息检索、社区问答，其中：\n\n(a)知识库问答通过查询冬奥领域知识图谱，来获取与实体相关的答案；\n\n(b)社区问答通过问题-问题匹配和问题-答案匹配，去配置好的问答库中检索答案；\n\n(c)互联网信息检索通过实时搜寻互联网页面，从而获取到与当前问题有关的必要信息。\n\n4.（橘黄部分）第四部分是多轮对话管理模块，可使得系统具备多轮对话的功能。如图所示，在与用户连续的对话中，系统能够不断追踪当前的对话焦点，以及与对话焦点相关的一系列属性，并依次作出智能的回复。","tags":[],"title":"面向2022冬残奥视障人群的多轮人机对话与情感分析","type":"project"}]