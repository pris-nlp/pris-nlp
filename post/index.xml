<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>所有博客 | 自然语言处理徐蔚然老师研究组</title>
    <link>https://pris-nlp.github.io/post/</link>
      <atom:link href="https://pris-nlp.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>所有博客</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>zh-Hans</language><copyright>© PRIS-NLP 2022</copyright><lastBuildDate>Mon, 25 Apr 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://pris-nlp.github.io/images/icon_hu316c76060153165bc5df614349754290_164774_512x512_fill_lanczos_center_3.png</url>
      <title>所有博客</title>
      <link>https://pris-nlp.github.io/post/</link>
    </image>
    
    <item>
      <title>DOP-Tuning: 面向对话摘要领域自适应的轻量级微调方法</title>
      <link>https://pris-nlp.github.io/post/220426zwh/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://pris-nlp.github.io/post/220426zwh/</guid>
      <description>&lt;p&gt;本文介绍一下我们组在面向领域迁移的对话摘要任务上的工作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-motivations&#34;&gt;1. Motivations&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;当前的对话摘要模型往往缺乏在新领域上的泛化性，因为大规模的生成式预训练模型往往需要大量的人工标注的黄金摘要，在 few/no labeled 的场景下无法扩展到新的领域。&lt;/li&gt;
&lt;li&gt;当前研究摘要领域迁移的方法需要耗时的预训练和大规模额外的语料库。他们仅关注沉重的预训练步骤而不是轻量化的微调过程。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;2-contributions&#34;&gt;2. Contributions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;我们第一个探索面向领域迁移的对话摘要任务的fine-tuning方法，并且在TODSum(TODSum是我们提出的对话摘要数据集
&lt;a href=&#34;https://arxiv.org/abs/2110.12680&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TODSum&lt;/a&gt;)和QMSum两个数据集上建立了实用且全面的benchmarks.&lt;/li&gt;
&lt;li&gt;提出了轻量且有效的面向领域的PrezZfix-tuning的模型，该模型使用领域词初始化的prefix模块以及离散的prompt来从大规模预训练模型中交互式地提取知识。&lt;/li&gt;
&lt;li&gt;进行了充分的实验和定量分析来证明了我们提出的方法的有效性，并且讨论了面向领域迁移的对话摘要所存在的挑战。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;3-methodology&#34;&gt;3. Methodology&lt;/h2&gt;
&lt;p&gt;模型结构包括Domain-Oriented Prefix，Prompt Encoder以及Decoder三个部分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165057557-fda144c5-1bd3-4929-81c7-5671ab32ae79.png&#34; alt=&#34;89601b192ff24bbcb37aaf8f1b2338c6&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;31-domain-oriented-prefix&#34;&gt;3.1 Domain-Oriented Prefix&lt;/h3&gt;
&lt;p&gt;为了缓解领域耦合的问题，我们提出了domain-oriented的prefix模块来从源域和目标域中获取共享的知识。
采用two-step构建Domain-Oriented Prefix，包括初始化和参数化。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165057725-487201b1-46da-45f1-88a0-b529f04d6bb5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;311-initialization&#34;&gt;3.1.1 Initialization&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;利用LDA主题模型从对话文本中提取每个领域的关键词，并且将他们拼接起来构成domain word（prefix）序列$x_{dw}$&lt;/li&gt;
&lt;li&gt;随机初始化domain word序列组成可学习的矩阵$M_{\theta}\in R^{|x_{dw}|d_{m}}$&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;312-parametrization&#34;&gt;3.1.2 Parametrization&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;利用MLP和预训练的BART模型分别得到domain word序列的表示，重新训练MLP使用MSE loss使得MLP的输出与预训练的BART的decoder hidden states相同，以此从预训练模型中解藕出领域知识。&lt;/li&gt;
&lt;li&gt;在更新MLP参数的过程中保持预训练的BART的参数固定。&lt;/li&gt;
&lt;li&gt;得到MLP的参数初始化，并使用预训练好的MLP来映射prefix表示的初始化embeddings.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;32-prompt-encoder&#34;&gt;3.2 Prompt Encoder&lt;/h3&gt;
&lt;h4 id=&#34;321-discrete-prompts&#34;&gt;3.2.1 Discrete Prompts&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;将TODSum数据集中的对话状态和QMSum中的queries作为离散的Prompts&lt;/li&gt;
&lt;li&gt;对于对话状态这种结构化的信息，将结构化的信息转化为文本序列。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;322-transformer-layer&#34;&gt;3.2.2 Transformer Layer&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;将离散的prompt序列$x_{dp}$以及对话文本序列$x_{d}$作为encoder的输入序列。&lt;/li&gt;
&lt;li&gt;通过修改添加domain-oriented prefix序列的键值对来修改self- attention机制。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;33-decoder&#34;&gt;3.3 Decoder&lt;/h3&gt;
&lt;p&gt;将Prefix模块也加到decoder上，以类似的方式修改cross-attention和self- attention机制。&lt;/p&gt;
&lt;h3 id=&#34;34-training-strategy&#34;&gt;3.4 Training Strategy&lt;/h3&gt;
&lt;p&gt;采用如下的训练目标更新梯度：&lt;/p&gt;
&lt;img width=&#34;805&#34; alt=&#34;e57e9ff9765e44f4b4e0a87ac6af44b3&#34; src=&#34;https://user-images.githubusercontent.com/47687248/165057976-c37eca89-bb9f-4c11-8b84-3fb21ba68e84.png&#34;&gt;
&lt;p&gt;在训练过程中中固定BART的参数，而更新prefix的参数。在训练时使用来自源域的领域词作为prefix序列。当训练完成以后，保存domain-oriented的prefix模块的参数，而丢弃掉预训练好的BART模块的参数。
在测试的过程中，目标域的领域词则被MLP模块映射为prefix表示。&lt;/p&gt;
&lt;h2 id=&#34;4-experimental-setup&#34;&gt;4. Experimental Setup&lt;/h2&gt;
&lt;h3 id=&#34;41--datasets&#34;&gt;4.1  Datasets&lt;/h3&gt;
&lt;p&gt;在两个multi-domain对话摘要数据集上评估了模型的效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058127-321b66bc-711d-4f98-ac63-a45438f05462.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;411-todsum&#34;&gt;4.1.1 TODSum&lt;/h4&gt;
&lt;p&gt;TODSum是基于经典对话数据集MultiWOZ提出的task-oriented对话摘要数据集。根据领域信息，数据集可以被划为5个领域：restaurant，hotel，attraction，taxi以及train. 在实验时，选择5个域中的4个域作为源域，剩下的域作为目标域，从源域中抽取200个样本作为验证集，源域的剩余数据作为训练集，目标域的数据作为测试集。&lt;/p&gt;
&lt;h4 id=&#34;412-qmsum&#34;&gt;4.1.2 QMSum&lt;/h4&gt;
&lt;p&gt;QMSum数据集包括上千条会议录音数据，包括三个领域：academic，committee以及product. 采用类似于TODSum数据集的处理方式。&lt;/p&gt;
&lt;h3 id=&#34;42-main-results&#34;&gt;4.2 Main Results&lt;/h3&gt;
&lt;h4 id=&#34;421-results-on-todsum&#34;&gt;4.2.1 Results on TODSum&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058282-6f033a85-410c-410b-b48d-214a72a22313.png&#34; alt=&#34;4dbdb43c2e3142fd92523ca9aadec458&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，Prefix-Tuning相比较BART，BART w. DS.,表现要差，是因为对话文本很长且复杂，仅使用fine-tuning参数的20%很难理解领域知识，以及识别对话中的关键内容。在与Prefix-tuning具有相同量级的参数下，DOP- tuning在5个领域都有了较大的提升。这表明由领域词初始化的prefix模块以及有对话状态组成的离散的prompts发挥了重要的作用。除此之外，模型比全参数fine-tuning的模型BART要好，说明模型可以有效地从源域和目标域中解藕出知识。上述结果表示，在有限的数据情况下，模型仍然可以达到SOTA的结果。&lt;/p&gt;
&lt;h4 id=&#34;422-results-on-qmsum&#34;&gt;4.2.2 Results on QMSum&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058369-d1f8c780-8583-4396-b467-64d05c6b731d.png&#34; alt=&#34;b22e45cf03554374808330cbc773fe30&#34;&gt;&lt;/p&gt;
&lt;p&gt;整体表现的趋势与在TODSum数据集上的表现一致，但是可以看出在Rouges的分数相对而言较低，是因为领域并没有明显的领域词，导致了严重的领域耦合的问题。除此之外，由于会议文本过长，很难从对话中捕捉核心内容。总的来说，这些结果表明多领域设置对于会议摘要是非常必要且有意义的。&lt;/p&gt;
&lt;h2 id=&#34;5-qualitative-analysis&#34;&gt;5. Qualitative Analysis&lt;/h2&gt;
&lt;h3 id=&#34;51-number-of-domain-words&#34;&gt;5.1 Number of Domain Words&lt;/h3&gt;
&lt;p&gt;探究领域词数量的影响，可以看到领域词数量在140时使rouge达到了峰值，当低于140时，效果降低，说明参数量不足影响了模型的表现。当领域词数量超过阈值时，模型的表现下降，说明了太长的prefix序列给BART增加了负担，并且引入了额外的噪声。但是，领域词数量的变化并没有对模型的表现的有太大的影响（只有2～3%的起伏），说明了domain-oriented prefix模块和有效性和模型的鲁棒性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058462-5b0df7ca-b9cd-4e50-a36d-15d195fbc629.png&#34; alt=&#34;f31ac144b97549aa90d84813653b4ac8&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;52-quality-of-domain-words&#34;&gt;5.2 Quality of Domain Words&lt;/h3&gt;
&lt;p&gt;探究领域词的质量的影响，将领域词的中的一定比例的词语以与领域无关的词汇替代。可以看到，随着更多的噪声被引入，模型受到更大的影响且表现下降。当噪声的比例超过100%时，模型的表现甚至比Prefix- Tuning糟糕。这是因为，我们使用完全无关的词汇去初始化Prefix模块，相比较随机初始化引入了更多的噪声影响了DOP的表现。从这一点看，引入高质量的领域词有利于领域解藕，高质量的领域词对摘要生成是重要的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058527-b933ad77-3137-4b9d-ba45-ed3ec737cd1d.png&#34; alt=&#34;3303ad68395040e68b08203f4ac28d90&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;53-ablation-study&#34;&gt;5.3 Ablation Study&lt;/h3&gt;
&lt;p&gt;研究了domain-oriented initialization和discrete prompts的影响。同时去掉两个模块与原始prefix-tuning相同。可以看到去除prefix- tuning中的domain- oriented初始化会使模型表现严重下降，说明domain word信息在面对新领域时引入相关知识的重要性。同时，移除离散的prompts也会使模型表现更糟糕（但仍然会好于Prefix-Tuning），说明离散的prompts能让模型更关注对话中核心的内容进而提升模型的表现。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058585-f8e3dd24-9f68-4cc5-b0cb-670ddb698351.png&#34; alt=&#34;faf6a973a06d4f64bd74f3c99becce12&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;54-effect-of-prefix-module-in-encoder-and-decoder&#34;&gt;5.4 Effect of Prefix Module in Encoder and Decoder&lt;/h3&gt;
&lt;p&gt;由于DOP-method在encoder和decoder中均引入了prefix模块，研究两个部分的prefix模块对模型表现的影响。可以看到，当两个部分的prefix被移除后，模型的表现均下降，说明了两个模块的prefix都是必要且高效的。&lt;/p&gt;
&lt;p&gt;一个有趣的现象是移除encoder的prefix的影响要小于移除decoder的prefix的影响。一个比较合理的解释是在encoder和decoder端的prefix的作用是不一样的。在encoder端的prefix主要帮助模型理解对话，而decoder端的prefix主要帮助模型生成。因此，对于摘要生成，decoder端的prefix模块对模型更有用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058661-66e0bf75-3766-41ed-9cf9-448b5e443e3a.png&#34; alt=&#34;4e9bda3719bb4c9bb210b920ab907f58&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;55-human-evaluation&#34;&gt;5.5 Human Evaluation&lt;/h3&gt;
&lt;p&gt;对模型进行了人工评估。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058716-dcb18574-ec70-40d7-ac51-725654fd3cd4.png&#34; alt=&#34;f757f1261bda4bceb881baa790173595&#34;&gt;&lt;/p&gt;
&lt;p&gt;表中显示，所有模型的流畅程度都较高，说明在较强的backbone上微调的抽象摘要模型能够生成更流畅的句子。在事实一致性上，DOP以及BART ws DS好于Prefix-tuning的表现，说明对话状态信息能引导模型更关注与核心的信息，例如槽值和意图。初次之外，DOP-tuning在领域相关性上的表现超过了其他基线模型。说明了domain-oriented模块在提升模型识别领域相关特征以及从源域和目标域解藕出知识的能力。&lt;/p&gt;
&lt;h3 id=&#34;56-effect-of-training-data&#34;&gt;5.6 Effect of Training Data&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058800-9f6323d4-ac48-406a-b256-017a18156ae4.png&#34; alt=&#34;20f9b8d72e8844abb49c580b1e47bdea&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;561-performance-in-few-shot-settings&#34;&gt;5.6.1 Performance in Few-shot Settings&lt;/h4&gt;
&lt;p&gt;对于TODSum数据集，固定源域的数据规模，将目标域的数据加入训练数据。可以看到随着目标域数据的增加，BART w. DS和DOP的表现提升，但DOP-tuning始终好于BART w. DS. 说明目标域的知识增加可以让模型学到目标域的信息。&lt;/p&gt;
&lt;h4 id=&#34;562-effect-of-source-domain-data-size&#34;&gt;5.6.2 Effect of Source Domain Data Size&lt;/h4&gt;
&lt;p&gt;保持zero-shot的设置不变，调整源域数据的规模&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058855-56a9767a-da09-4f77-aee4-6c83e43c58b0.png&#34; alt=&#34;fca012c5f1e441718b2181ace0c80153&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到随着数据规模的减小，BART w. DS的表现变差，而DOP-tuning能够相对优秀地保持稳定。说明DOP-tuning对数据规模不太敏感，并且具有一定程度的鲁棒性。这与主实验的结果一致，模型在有限和unseen data上表现优异。&lt;/p&gt;
&lt;h3 id=&#34;57-prefix-length-vs-input-length&#34;&gt;5.7 Prefix Length vs. Input Length&lt;/h3&gt;
&lt;p&gt;研究Prefix Length和input Length的关系，具体而言source input length，target input length以及对应的optimal prefix length的关系。可以得出更长的inputs可能更青睐于更短的prefix.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47687248/165058896-b39fa528-04f3-4dd6-85da-a32c49d54a81.png&#34; alt=&#34;1d1a29e6f80b4d3b90e22b10c45c5215&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;6-challenges&#34;&gt;6. Challenges&lt;/h2&gt;
&lt;p&gt;总结了抽象对话摘要的低资源领域迁移的挑战：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Confusion between domains with high similarity
对于词汇表高度重合的领域，如restaurant和hotel，train和taxi，模型会产生domain-confusing句子。以hotel- restaurant对作为例子，当restaurant作为目标域，“book a restaurant room that can accommodate 3 people”会被生成，这样的句子其实更应该存在hotel领域中。但需要注意的是，这种challenge并不会影响关键因素的准确率，但language style则是不合适的。&lt;/li&gt;
&lt;li&gt;Information dispersion
由于对话数据通常是长序列，因此模型很难对长对话中的所有方面都能pay attention，因此会产生对话中关键元素的注意力的偏差，尤其是在轻量和小参数训练的场景下。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;7-conclusion&#34;&gt;7. Conclusion&lt;/h2&gt;
&lt;p&gt;在本文中，我们提出了基于高效且可泛化的微调方法面向领域的domain-oriented prefix-tuning模型解决对话摘要中的领域迁移的方法。使用领域词初始化的prefix模块能够从源域解藕出目标域的知识，而离散的prompts能够提升模型的泛化性。在zero-shot和few-shot下的实验说明我们的方法在两个数据集下取得了巨大的进步。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>本研究组近期研究速览</title>
      <link>https://pris-nlp.github.io/post/220408wzc/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://pris-nlp.github.io/post/220408wzc/</guid>
      <description>&lt;h2 id=&#34;adpl-adversarial-prompt-based-domain-adaptation-for-dialogue-summarization-with-knowledge-disentanglement&#34;&gt;&lt;strong&gt;ADPL: Adversarial Prompt-based Domain Adaptation for Dialogue Summarization with Knowledge Disentanglement&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;论文作者&#34;&gt;论文作者&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/author/%E8%B5%B5%E7%92%90%E7%92%90/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;赵璐璐&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E9%83%91%E9%A6%A5%E5%98%89/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑馥嘉&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E6%9B%BE%E4%BC%9F%E8%B1%AA/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾伟豪&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E4%BD%95%E5%8F%AF%E6%B8%85/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E8%80%BF%E8%8B%A5%E5%BD%A4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;耿若彤&lt;/a&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%BE%90%E8%94%9A%E7%84%B6/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;发表会议&#34;&gt;发表会议&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://sigir.org/sigir2022/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SIGIR 2022&lt;/a&gt; Full Paper&lt;/p&gt;
&lt;h4 id=&#34;论文简介&#34;&gt;论文简介&lt;/h4&gt;
&lt;p&gt;领域自适应是机器学习中的一个基本任务。在本文中，我们研究对话摘要任务中的领域迁移问题，试图借助源域的有标注数据迁移到无标注或少标注的目标域，进而提升低资源目标域下对话摘要的生成效果，可用于解决实际场景中小业务数据匮乏的挑战。传统的对话摘要领域迁移方法往往依赖于大规模领域语料，借助于预训练来学习领域间知识。该方法的缺点是实际语料收集难，对算力要求高，针对每一个目标域都需要进行耗时的预训练过程，效率低。因此，本文从微调的角度出发，提出了一种轻量级的解耦知识迁移方法ADPL，无需大规模的预训练过程，仅仅利用源域数据和少量的无标注目标域数据，即可实现高质量的对话摘要生成。具体来说，我们基于prompt learning的思想，针对对话摘要任务中的领域迁移问题，提出了三种特定的prompt结构：domain-invariant prompt (DIP), domain-specific prompt (DSP), 和task-oriented prompt (TOP)，其中 DIP 用来捕获领域间的共享特征，DSP用来建模领域特有知识，TOP用来促进生成流畅的摘要。在训练中，我们仅仅更新这些prompt相关的参数就可以实现领域间知识的解耦和迁移，相比较之前的预训练方法，训练高效环保，对机器的显存要求显著降低。同时，我们基于两个大规模的对话摘要数据集QMSum和TODSum构建了对话摘要领域迁移评测集，在两个评测集上取得了一致的最优效果，实验结果和消融分析都证明了本文提出方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;center&gt;&lt;font face=&#34;黑体&#34; size=3&gt;ADPL整体框架示意图&lt;/font&gt;&lt;/center&gt;
&lt;hr&gt;
&lt;h2 id=&#34;revisit-overconfidence-for-ood-detection-reassigned-contrastive-learning-with-adaptive-class-dependent-threshold&#34;&gt;&lt;strong&gt;Revisit Overconfidence for OOD Detection: Reassigned Contrastive Learning with Adaptive Class-dependent Threshold&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;论文作者-1&#34;&gt;论文作者&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%90%B4%E4%BA%9A%E6%A5%A0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;吴亚楠&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E4%BD%95%E5%8F%AF%E6%B8%85/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E4%B8%A5%E6%B8%8A%E8%92%99/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;严渊蒙&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E9%AB%98%E7%90%AA%E7%BF%94/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;高琪翔&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E6%9B%BE%E8%87%B4%E8%BF%9C/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾致远&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E9%83%91%E9%A6%A5%E5%98%89/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑馥嘉&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E8%B5%B5%E7%92%90%E7%92%90/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;赵璐璐&lt;/a&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%BE%90%E8%94%9A%E7%84%B6/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;发表会议-1&#34;&gt;发表会议&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://2022.naacl.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NAACL 2022&lt;/a&gt; Main Conference, Long Paper&lt;/p&gt;
&lt;h4 id=&#34;论文简介-1&#34;&gt;论文简介&lt;/h4&gt;
&lt;p&gt;在面向任务的对话系统中，域外意图（out-of-domain, OOD）检测是必不可少的。它旨在检测用户查询是否超出预定义意图范围（in-domain, IND），以避免执行错误的操作。由于OOD意图标注的复杂性，大多数工作都集中在无监督OOD检测上，即没有标记OOD数据，只有标记IND数据。而当前无监督域外检测方法均忽略了域外检测中的关键性挑战——神经网络的过自信问题。&lt;/p&gt;
&lt;p&gt;在本文中，我们对过自信问题进行了深入分析，并将其拆解为两方面：过自信OOD和过自信IND。基于此，我们分别提出了一种新的重分配对比学习(RCL)来区分语义相似的IND类别之间的意图表示，以缓解过自信OOD问题，以及一种自适应的类局部阈值机制来区分相似的IND和OOD样本，以缓解过自信IND问题。&lt;/p&gt;
&lt;p&gt;具体来说，对于过自信OOD问题，我们首先使用预训练的意图分类器在易混淆的IND类型中构建hard对比对（其中，具有相同真实标签但不同的预测标签称为hard positive pair，不同真实标签但相同预测标签称为hard negative pair），然后，基于构建的对比对训练一个新的模型，并通过监督对比学习来学习相似IND类别的鉴别性意图表示；对于过自信IND问题，不同于传统MSP、GDA使用单一全局阈值的方式，为考虑IND和OOD类别之间的关联性，我们为每个意图类别自适应赋予一个独立阈值，有效区分语义高度相似的IND和OOD样本，缓解过自信OOD问题。多个数据集上实验和分析证明了本文提出方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;domain-oriented-prefix-tuning-towards-efficient-and-generalizable-fine-tuning-for-zero-shot-dialogue-summarization&#34;&gt;&lt;strong&gt;Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;论文作者-2&#34;&gt;论文作者&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/author/%E8%B5%B5%E7%92%90%E7%92%90/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;赵璐璐&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E9%83%91%E9%A6%A5%E5%98%89/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑馥嘉&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E6%9B%BE%E4%BC%9F%E8%B1%AA/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾伟豪&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E4%BD%95%E5%8F%AF%E6%B8%85/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%BE%90%E8%94%9A%E7%84%B6/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%90%B4%E4%BA%9A%E6%A5%A0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;吴亚楠&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;发表会议-2&#34;&gt;发表会议&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://2022.naacl.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NAACL 2022&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;论文简介-2&#34;&gt;论文简介&lt;/h4&gt;
&lt;p&gt;现实生活中经常面临到新领域中数据标注稀缺的问题，为新领域进行标注耗时耗力，因此利用有限的源域注释数据为目标域开发低资源对话摘要模型至关重要。当前的生成式对话摘要方法缺乏对新领域的泛化能力，而现有的在摘要领域自适应问题上的研究通常是依赖于大规模的二次预训练。&lt;/p&gt;
&lt;p&gt;为了探索对话摘要领域自适应的轻量级微调方法，在本文中，我们提出了一种高效且可泛化的面向领域的Prefix-tuning模型（Domain-Oriented Prefix-tuning，DOP），在冻结的预训练模型的基础上，结合连续的prefix和离散的prompt表示，提高模型的领域自适应能力。具体来说，我们使用无监督 LDA提取的领域词来初始化连续提示向量，以获得前缀模块的初始参数和表示。我们还添加了一个面向领域的键值对前缀序列来增强经典注意力层，以交互方式获取知识并实现优化。除此之外，我们使用dialogue state和query作为离散prompt，引导模型关注对话中关键内容并增强对新领域的泛化能力。&lt;/p&gt;
&lt;p&gt;我们在两个多域对话摘要数据集 TODSum 和 QMSum 上进行零样本迁移实验并建立领域自适应benchmark， 充分的实验和定性分析证明了我们方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;disentangled-knowledge-transfer-for-ood-intent-discovery-with-unified-contrastive-learning&#34;&gt;&lt;strong&gt;Disentangled Knowledge Transfer for OOD Intent Discovery with Unified Contrastive Learning&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;论文作者-3&#34;&gt;论文作者&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://pris-nlp.github.io/author/%E7%89%9F%E5%AE%87%E6%BB%94/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;牟宇滔&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E4%BD%95%E5%8F%AF%E6%B8%85/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;何可清&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%90%B4%E4%BA%9A%E6%A5%A0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;吴亚楠&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E6%9B%BE%E8%87%B4%E8%BF%9C/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾致远&lt;/a&gt;，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%BE%90%E7%BA%A2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐红&lt;/a&gt;，江会星，武威，
&lt;a href=&#34;https://pris-nlp.github.io/author/%E5%BE%90%E8%94%9A%E7%84%B6/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;徐蔚然&lt;/a&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;发表会议-3&#34;&gt;发表会议&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.2022.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL 2022&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;论文简介-3&#34;&gt;论文简介&lt;/h4&gt;
&lt;p&gt;本文研究域外(OOD)意图发现任务，该任务旨在将新出现的未知意图的样本按意图语义聚成不同类簇，这有助于任务型对话系统发展新的技能。不同于传统的文本聚类任务，域外意图发现需要考虑如何利用已知的域内(IND)意图类别的先验知识，帮助新意图的聚类。因此相关方法都遵循一个两阶段框架：IND预训练和OOD聚类。其中的关键挑战在于如何将IND先验知识迁移到OOD聚类上。之前的方法普遍存在一个问题，将IND预训练过程当作分类任务，采用一个交叉熵分类损失，模型学习到如何分类IND样本，但是下游我们需要对OOD聚类。两个阶段不同的学习目标使得存在一个天然的语义鸿沟，使得IND到OOD的知识迁移变得困难。此外，我们观察到之前的方法只迁移BERT输出的一个共享意图表征，考虑到表征具有高度耦合性，这样一个表征可能不利于OOD聚类。例如，在IND预训练的编码器中存在实例级(instance-level)和聚类级(class-level)的知识，解耦不同级别的知识有助于更好地知识迁移。为了解决这样的问题，我们建立了一个统一的多头对比学习框架，并在此基础上提出了一个新颖的解耦知识迁移方法(DKT)，以便迁移解耦IND意图知识用于OOD聚类。我们意在弥合IND预训练和OOD聚类两个阶段的语义鸿沟。两个基准数据集的实验和分析显示了我们方法的有效性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;同等贡献&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;通讯作者&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Measure and Improve Robustness in NLP Models: A Survey</title>
      <link>https://pris-nlp.github.io/post/211227wzc/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://pris-nlp.github.io/post/211227wzc/</guid>
      <description>&lt;!-- 如果你想外链到其他博客分享论文，插入超链接即可
[一个帅哥的论文分享](https://helicqin.github.io/2021/08/08/Modeling%20Fine-Grained%20Entity%20Types%20with%20Box%20Embeddings/) --&gt;
&lt;!-- 当然你也可以直接在这里写博客，像下面这样 --&gt;
&lt;p&gt;本文是一片关于NLP模型鲁棒性的综述，统一地介绍了如何定义、衡量和提升NLP模型的鲁棒性。&lt;/p&gt;
&lt;h2 id=&#34;nlp模型鲁棒性的定义&#34;&gt;NLP模型鲁棒性的定义&lt;/h2&gt;
&lt;p&gt;模型在$(x, y) \sim \mathcal{D}$上训练，在$(x&#39;, y&#39;)\sim \mathcal{D&#39;} \ne \mathcal{D}$
上测试，可以用模型在$\mathcal{D&#39;}$上的性能（如准确率）衡量模型的鲁棒性。&lt;/p&gt;
&lt;p&gt;可以粗略地将现有的模型鲁棒性的文献分为两类：$\mathcal{D&#39;}$是对输入合成扰动，或者
$\mathcal{D&#39;}$是自然发生的分布转移。&lt;/p&gt;
&lt;h3 id=&#34;对对抗攻击的鲁棒性&#34;&gt;对对抗攻击的鲁棒性&lt;/h3&gt;
&lt;p&gt;对抗攻击是指故意精心制造噪声来欺骗模型做出错误的预测，之前在CV领域被广泛探索，
后来扩展到NLP领域。对抗样本的生成主要建立在这样一个观察之上，即我们可以生成对人类有意义的样本(例如，通过用人类察觉不到的变化干扰样本)，同时改变对该样本的模型预测。
对抗攻击主要建立在人类可以理解大量同义词或者忽略字母的确切顺序，但机器不能。&lt;/p&gt;
&lt;p&gt;现在大多数CV研究都做了一个相对简单的假设，即在$x$上加有界摄动得到的$x&#39;$的金标应该保持不变，
即$y&#39;=y$，模型的鲁棒行为应该是$f(x&#39;)=f(x)$。其中的摄动可以是token和字符的交换，释义，
不改变语义的对抗规则，或者添加干扰因素。&lt;/p&gt;
&lt;p&gt;然而，这个标签不变的假设可能并不总是成立的，有人研究了几种现有的文本扰动技术，但发现
一大部分扰动样本都改变了标签（尽管是在保留标签的假设下）或者结果的标签在人类标注者中
存在高度分歧。&lt;/p&gt;
&lt;p&gt;还有一个相似的概念是语义保留，是指$(x, x&#39;)$之间的语义是不变的，而上面的标签保留是指
$(y, y&#39;)$是不变的。&lt;/p&gt;
&lt;h3 id=&#34;对分布转移的鲁棒性&#34;&gt;对分布转移的鲁棒性&lt;/h3&gt;
&lt;p&gt;现有的鲁棒性定义更接近域泛化或OOD泛化的概念，其中测试集（不管有无标签）都是在训练的时候
不可获取的。
在NLP背景下，对自然分布转移的鲁棒性也意味着模型的性能不会因为语法错误、方言、说话者和
语言的差异或者为同一任务不同领域新收集的数据集而降低。&lt;/p&gt;
&lt;p&gt;另一个密切相关的研究方向是公平性，例如，在指代消解、职业分类、神经机器翻译等任务中观察到了性别刻板印象或偏差。&lt;/p&gt;
&lt;h3 id=&#34;联系和共同主题&#34;&gt;联系和共同主题&lt;/h3&gt;
&lt;p&gt;合成
上述两个分类都可以归为一个框架中，即$\mathcal{D&#39;}$代表合成分布转移（通过对抗攻击）或自然分布转移。
两者的联系仍有待探索。在CV领域，有研究表面对合成分布转移的鲁棒性可能对自然分布转移鲁棒性贡献
很少甚至没有贡献。&lt;/p&gt;
&lt;p&gt;为了更好地理解模型为什么缺乏鲁棒性，一些现有的工作认为这是因为模型有时利用虚假的特征和标签之间的
关系，而非真正的关系。其中虚假的特征通常定义为并不真正影响任务标签的特征。它们和任务标签有联系，但是不能转移到更加有挑战性的测试条件或OOD数据。一些其他的工作将其定义为适用于大多数情况但不适用于一般情况的规则。这些虚假的关系有时被称为数据集偏差或群体转移。此外，有证据表明，控制模型在虚假特征下的学习将提高模型在分布转移中的性能。还有学者讨论了对抗鲁棒性和伪特征学习之间的联系。还有人通过将模型在分布转移或对抗性攻击中缺乏鲁棒性的原因归因于模型对虚假特征的学习，提出了连接这些领域的理论性的讨论。&lt;/p&gt;
&lt;p&gt;此外，在某些应用中，模型的鲁棒性也可以与模型的不稳定性或者模型的不确定度估计很差联系起来。
对于此，有人提出了贝叶斯方法、基于dropout和基于组装的实现方法。最近，Ovadia等人已经证明，模型的不确定性估计可能在分配转移下显著降低，并呼吁应当通过对OOD数据给出更低的不确定性估计，确保
模型“知道它什么时候不知道”。&lt;/p&gt;
&lt;h2 id=&#34;识别非鲁棒&#34;&gt;识别非鲁棒&lt;/h2&gt;
&lt;p&gt;随着鲁棒性在自然语言处理文献中得到越来越多的关注，各行各业都提出了识别自然语言处理模型鲁棒性失效的方法。现有工作可以根据故障的识别方式大致分类，其中很大一部分工作依赖于人类先验和对现有NLP模型的错误分析，其他一些工作线采用基于模型的方法。为了更准确地度量自然语言处理模型的鲁棒性，通常将识别出的鲁棒性失效模式组织成具有挑战性/对抗性的基准数据集。表1展示了用于识别模型鲁棒性失效的常用扰动类型（数据集），在表2中，我们总结了每个NLP任务的常见鲁棒性基准（benchmark）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://s2.loli.net/2021/12/27/vwJmq2xBXTMHcfO.png&#34; alt=&#34;fig&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;人类先验和错误分析驱动的&#34;&gt;人类先验和错误分析驱动的&lt;/h3&gt;
&lt;p&gt;按任务分，包括NLI（Natural Language Inference），QA和神经机器翻译。&lt;/p&gt;
&lt;h4 id=&#34;nli&#34;&gt;NLI&lt;/h4&gt;
&lt;p&gt;Naik等人抽样错误分类的例子，并分析其潜在的错误来源，然后将其归类为常见错误原因的类型。这些错误类型将作为构建压力测试集的基础，以进一步评估NLI模型是否具有做出真实推理决策的能力，还是仅仅依赖于复杂的模式匹配。Gururangan等人发现，目前的NLI模型很可能仅依靠假设来识别标签，而Poliak等人提供了类似的补充，即我们采用仅假设的模型可以优于一组强基线。&lt;/p&gt;
&lt;h4 id=&#34;qa&#34;&gt;QA&lt;/h4&gt;
&lt;p&gt;有人提出通过在段落末尾串联一个敌对的干扰句来生成敌对的QA例子。Miller等人为斯坦福问答数据集(SQuAD)构建了四个新的测试集，并发现大多数问答系统未能推广到这一新的数据。他们也希望对自然分布转移进行新的评估指标。&lt;/p&gt;
&lt;h4 id=&#34;机器翻译&#34;&gt;机器翻译&lt;/h4&gt;
&lt;p&gt;Belinkov和Bisk发现，当面对嘈杂数据时，基于字符的神经机器翻译(NMT)模型是脆弱的，很容易不稳定，其中噪音(例如，打字、拼写错误等)是使用可能的词汇替换合成的。使用包含人工引入语法错误的句子或随机合成噪音的增强训练数据可以使系统对这种虚假模式更加稳健。另一方面，有人展示了另一种方法，通过限制字符的输入空间，使模型有可能感知数据输入错误和拼写错误。&lt;/p&gt;
&lt;h3 id=&#34;基于模型的&#34;&gt;基于模型的&lt;/h3&gt;
&lt;p&gt;这种方法有的是任务不确定的，有的是输入不可知的。
这种方法通过训练一个额外的模型来捕获偏差。例如，在视觉问题回答中，Clark等人训练一个朴素模型来预测基于问题的原型答案，而不考虑上下文;Utama等人提出学习一个仅使用数据集偏差相关特征的有偏模型。此外，Culotta的目标是通过训练分类器来识别模型中的捷径，从而从人类标注的例子中更好地区分虚假的相关性和真实的相关性。&lt;/p&gt;
&lt;h2 id=&#34;提升模型鲁棒性&#34;&gt;提升模型鲁棒性&lt;/h2&gt;
&lt;p&gt;根据人工干预的位置和方式，这些方法可以分为数据驱动的、基于模型和训练方案的、基于归纳先验和最后的因果干预。&lt;/p&gt;
&lt;h3 id=&#34;数据驱动数据增强&#34;&gt;数据驱动（数据增强）&lt;/h3&gt;
&lt;p&gt;如Mixup, MixText, CutOut, AugMix, HiddenCut。这类缓解方法是在数据层面上操作的，往往很难解释如何以及为什么起作用。&lt;/p&gt;
&lt;h3 id=&#34;基于模型和训练策略&#34;&gt;基于模型和训练策略&lt;/h3&gt;
&lt;h4 id=&#34;预训练&#34;&gt;预训练&lt;/h4&gt;
&lt;p&gt;最近的研究表明，预训练是提高NLP模型非分布鲁棒性的有效方法，这可能是因为其自我监督的目标，以及使用了大量不同的训练前数据，这些数据鼓励从少量的测试样本中归纳出一般化的结果，从而抵消了虚假的相关性。有研究显示一些其他因素也可以促进稳健的准确性，包括更大的模型尺寸、更多的微调数据和更长的微调。Taori等人在视觉领域也进行了类似的观察，其中作者发现，与现有文献提出的各种鲁棒性干预相比，使用更大、更多样化的数据集的训练在多个情况下提供了更好的鲁棒性。&lt;/p&gt;
&lt;h4 id=&#34;更好地利用少数群体的样本训练&#34;&gt;更好地利用少数群体的样本训练&lt;/h4&gt;
&lt;p&gt;还有一些工作建议通过更好地使用少数例子来简化模型，例如，在训练分布中代表性不足的例子，或更难学习的例子。例如，Yaghoobzadeh等人提出，首先根据全部数据对模型进行微调，然后只对少数例子进行微调。一般来说，强调样本子集的训练策略对模型来说特别难学习，有时也被称为DRO（distributional robust optimization，分布式鲁棒优化）组。DRO的扩展主要是讨论如何识别被认为是少数样本。例如，Nam等人通过强调模型的早期决策来训练另一个模型;Lahoti等人也使用另一个模型来识别对主模型具有挑战性的样本;Liu等人提出通过对在第一次训练时损失较大的少数例子增加权重，对模型进行第二次训练。&lt;/p&gt;
&lt;h3 id=&#34;基于归纳的实现方法&#34;&gt;基于归纳的实现方法&lt;/h3&gt;
&lt;p&gt;另一个思路是引入归纳偏差(即正则化假设空间)，迫使模型丢弃一些虚假的特征。这与基于人先验的识别方法密切相关，因为这些人的先验知识通常可以用额外的正则化器来重新制定训练目标。为了实现这一目标，通常需要首先构造一个侧组件来通知主模型有偏差的特征，然后根据侧组件来正则化主模型。这个侧组件的构造通常依赖于失调特征是什么的先验知识。然后，可以建立相应的方法来应对特征。类似地，Clark等人提出用一个显式捕获偏差的模型进行集成，其中主模型与这个仅偏差（bias-only）模型一起训练，这样主模型就不被鼓励使用偏差。最近的工作表明，通过更好地校准仅偏差模型，基于集成的方法可以进一步改进。&lt;/p&gt;
&lt;p&gt;总之，这种方法大概是在不同的领域/分布中训练小的经验损失，以迫使模型对特定领域的虚假特征不变。&lt;/p&gt;
&lt;h3 id=&#34;干预因果关系&#34;&gt;干预因果关系&lt;/h3&gt;
&lt;p&gt;Srivastava利用人类对因果关系的常识知识，以潜在的未测量变量来增加训练样本，并提出了一种基于DRO的方法，以使模型对分布转移具有鲁棒性。Veitch等人提出学习依赖于数据因果结构的估计反事实不变量预测，并表明它可以帮助减少文本分类中的虚假相关性。&lt;/p&gt;
&lt;h3 id=&#34;提升鲁棒性策略的联系&#34;&gt;提升鲁棒性策略的联系&lt;/h3&gt;
&lt;p&gt;大体可分为3类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;利用大量数据预训练模型&lt;/li&gt;
&lt;li&gt;学习跨领域/环境的不变表示或预测&lt;/li&gt;
&lt;li&gt;基于具体的虚假/偏见模式的数据&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有趣的是，统计研究表明，许多缓解方法都有相同的鲁棒机器学习泛化误差界。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
