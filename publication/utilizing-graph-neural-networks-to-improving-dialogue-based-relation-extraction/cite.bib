@article{ZHAO2021299,
title = {Utilizing graph neural networks to improving dialogue-based relation extraction},
journal = {Neurocomputing},
volume = {456},
pages = {299-311},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.05.082},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221008353},
author = {Lulu Zhao and Weiran Xu and Sheng Gao and Jun Guo},
keywords = {Dialogue-based relation extraction, Cross-sentence, Graph convolutional network, Dense connectivity},
abstract = {Relation extraction has been an active research interest in the field of Natural Language Processing (NLP). The past works primarily focused on a corpus of formal text which is inherently non-dialogic. Recently, the dialogue-based relation extraction task, which detects relations among speaker-aware entities scattering in dialogues, has been gradually arousing peopleâ€™s attention. Some sequence-based neural methods have been carried out to obtain the relevant information. However, identifying cross-sentence relations remains unsolved, especially in the context of a specific-domain dialogue system. In this paper, we propose a Relational Attention Enhanced Graph Convolutional Network (RAEGCN), which constructs the whole dialogue as a semantic interactive graph by emphasizing the speaker-related information and leveraging various inter-sentence dependencies. A dense connectivity mechanism is also introduced to empower the multi-hop relational reasoning across sentences, which can capture both local and non-local features simultaneously. Experiments show the significant superiority and robustness of our model on a real-world dataset DialogRE, as compared with previous approaches.}
}